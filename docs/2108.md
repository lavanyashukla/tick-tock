TITLE:
wandb sweep end after first run with RuntimeError('CUDA error: device-side assert triggered')

LABEL:
c:misc

STATE:
closed

BODY:
I am trying to use wandb sweep for hyperparameter search with simpletransformers following [this blog post](https://towardsdatascience.com/hyperparameter-optimization-for-optimum-transformer-models-b95a32b70949).
It runs perfectly for one run and then stops because of
`RuntimeError('CUDA' error: device-side assert triggered')`

Here is the code:
```
model_args = ClassificationArgs()

model_args.max_seq_length = 200
model_args.do_lower_case = True

model_args.n_gpu = len(use_gpus.split(','))
#model_args.train_batch_size = int(train_batch_size)
model_args.per_device_train_batch_size=5
model_args.num_train_epochs = 15
model_args.learning_rate = 4e-5
model_args.adam_epsilon = 1e-8
model_args.warmup_steps = 0
model_args.scheduler = "linear_schedule_with_warmup"
model_args.evaluate_during_training = True
model_args.evaluation_strategy = 'steps'
model_args.evaluate_during_training_steps = len(df_train)//model_args.per_device_train_batch_size//5
model_args.use_early_stopping = False
model_args.labels_list = [x for x in range(23)]
model_args.wandb_project = "Hyperparameter Optimization"
model_args.output_dir = "wandb_sweep/"
model_args.best_model_dir = "wandb_sweep/best_model/"
model_args.cache_dir = "wandb_sweep/cache_dir/"
model_args.reprocess_input_data = True
model_args.overwrite_output_dir = True
model_args.eval_batch_size = 5
model_args.save_model_every_epoch = False
model_args.save_steps = -1 
model_args.save_eval_checkpoints = False 

sweep_config = {
    "name": "vanilla-sweep",
    "method": "bayes",
    "metric": {"name": "accuracy", "goal": "maximize"},
    "parameters": {
        "num_train_epochs": {"min": 1, "max": 40},
        "learning_rate": {"min": 1e-6, "max": 1e-1},
    },
    "early_terminate": {"type": "hyperband", "min_iter": 6,},
}

sweep_id = wandb.sweep(sweep_config, project="IN simpletransformers WandB sweep")

def train():
    # Initialize a new wandb run
    wandb.init()

    # Create a TransformerModel
    model = ClassificationModel(
        "bert",
        "dbmdz/bert-base-italian-uncased",
        num_labels=len(label_dict),
        args=model_args,
        sweep_config=wandb.config,
    )

    # Train the model
    model.train_model(
        train_df=df_train,
        eval_df=df_val,
        accuracy=lambda truth, predictions: accuracy_score(
            truth, [round(p) for p in predictions]
        ),
    )

    # Sync wandb
    wandb.join()

wandb.agent(sweep_id, train)
```
I am using:
pytorch 1.7.1
wandb 0.10.27
simpletransformers 0.61.4


