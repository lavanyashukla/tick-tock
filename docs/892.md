TITLE:
Issue using agent with PyTorch+cuda

LABEL:
c:jupyter

STATE:
closed

BODY:
* Weights and Biases version: 0.8.28
* Python version: Python 3.6.9
* Operating System: Linux (Colab)

### Description

I'm trying to run a sweep in Colab. My model is in PyTorch and requires a GPU. It seems that the use of multiprocessing isn't compatible with PyTorch. I've created the below toy example to reproduce the bug. Any advice?

### What I Did

```
import wandb
import torch

def train():
  model = torch.nn.Linear(100,100)
  model.cuda()

sweep_id = wandb.sweep({
    'method': 'grid',
    'parameters': {
        'blah': {
            'values': [1]
        }
    }
})
wandb.agent(sweep_id, function=train)
```

Stacktrace:
```
Process Process-4:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.6/dist-packages/wandb/wandb_agent.py", line 64, in _start
    function()
  File "<ipython-input-23-3598f8bb2714>", line 6, in train
    model.cuda()
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 304, in cuda
    return self._apply(lambda t: t.cuda(device))
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 223, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 304, in <lambda>
    return self._apply(lambda t: t.cuda(device))
  File "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py", line 195, in _lazy_init
    "Cannot re-initialize CUDA in forked subprocess. " + msg)
RuntimeError: Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method
```

