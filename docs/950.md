TITLE:
Wandb Tensorboard logging takes 300-400% more time

LABEL:
c:misc

STATE:
closed

BODY:
`wandb --version && python --version && uname`

```
wandb, version 0.8.31
Python 3.7.4
Linux
```

### Description

Hope you guys are having a good day.

I am using wandb to manage my reinforcement learning experiments through Tensorboard. It is a brilliant tool, but it's slowing the program down significantly. In the `What I Did section`, I experimented with a script running for 861 episodes, so the following code is called for 861 times.

```python
writer.add_scalar("charts/episode_reward", rewards.sum(), global_step)
writer.add_scalar("charts/sigma", action_noise.sigma, global_step)
writer.add_scalar("losses/td_loss", td_losses[:step+1].mean(), global_step)
```

Using wandb to patch the tensorboard compared with not doing so results in the execution time to be **3m27.143s** and **0m45.095s**, respectively. As demonstrated, using wandb would make the program take (3*60 + 27) / 45 = **460%** more time. (also see public runs here https://app.wandb.ai/cleanrl/cleanRL/runs/jhyz6ni8?workspace=user-costa-huang)

I experimented with `wandb.tensorboard.configure(rate_limit_seconds=2)`, which definitely speeds up everything, but the behavior is not really desirable.

Is there anyway to control the syncing frequency instead of just the `rate_limit_seconds`?

Any help would be appreciated.

### What I Did

Here is a sample code to run (https://gist.github.com/vwxyzjn/af4374a46ac29535e7b747320fe10d79#file-td3_debug-py)

And I ran with 

```
time python td3_debug.py
# global_step=10024, episode_reward=48.12391943677841
# episode count 861
# real    0m45.095s
# user    1m22.050s
# sys     0m1.736s

time python td3_debug.py --prod-mode

# global_step=10024, episode_reward=48.12391943677841
# 861

# wandb: Waiting for W&B process to finish, PID 5527
# wandb: Program ended successfully.
# wandb: Run summary:
# wandb:              _timestamp 1585712247.4726121
# wandb:             global_step 10024
# wandb:                _runtime 200.48829102516174
# wandb:                   _step 861
# wandb:   charts/episode_reward 48.12392044067383
# wandb:          losses/td_loss 0.30098745226860046
# wandb:            charts/sigma 0.05000000074505806
# wandb: Syncing files in wandb/run-20200401_033407-jhyz6ni8:
# wandb:   code/cleanrl/experiments/td3_debug.py
# wandb:   td3_debug.py
# wandb: plus 8 W&B file(s) and 0 media file(s)
# wandb:                                                                                
# wandb: Synced HopperBulletEnv-v0__td3_debug__2__1585712046: https://app.wandb.ai/cleanrl/cleanRL/runs/jhyz6ni8

# real    3m27.143s
# user    1m41.158s
# sys     0m2.828s

```


