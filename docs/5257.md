TITLE:
[Q]Agent's configs not passing to args when sweeping timm training script

LABEL:
c:misc

STATE:
open

BODY:
I tried to sweep with timm([pytorch-image-models](https://github.com/huggingface/pytorch-image-models)) training script. 
I can clearly see from the terminal output that the parameters configs are not actually passing to train.py. 
e.g. I set   epochs:
    distribution: int_uniform
    max: 800
    min: 320
but when I run: wandb agent /swep/qm9shctr
The epoch is always set to 300, which is the default value in timm's train.py (:group.add_argument('--epochs', type=int, default=300, metavar='N',
                   help='number of epochs to train (default: 300)'))

Here is my Sweep configuration:


command:
  - /usr/bin/env
  - python
  - /home/wl/pycharmProjs/timm/train.py
  - --model=convnext_nano
  - --channels-last
  - --amp
  - --use-multi-epochs-loader
  - --save-images
  - --num-classes=3
  - --pretrained
  - --experiment=sweep
  - --batch-size=236
  - --data-dir=/data/wl/3bandsData/uint16pngs/
  - --opt=adamw
  - --aa=rand-m8-inc1-mstd101
  - --log-wandb
method: bayes
metric:
  goal: maximize
  name: rowd['eval_top1']
parameters:
  cooldown_epochs:
    distribution: int_uniform
    max: 20
    min: 5
  cutmix:
    distribution: int_uniform
    max: 2
    min: 1
  decay_epochs:
    distribution: int_uniform
    max: 200
    min: 50
  decay_rate:
    distribution: uniform
    max: 0.2
    min: 0.05
  drop:
    distribution: uniform
    max: 0.25
    min: 0.05
  drop_path:
    distribution: uniform
    max: 0.2
    min: 0.05
  epochs:
    distribution: int_uniform
    max: 800
    min: 320
  hflip:
    distribution: uniform
    max: 0.9
    min: 0.25
  lr:
    distribution: uniform
    max: 0.0015
    min: 0.0004
  lr_base:
    distribution: uniform
    max: 0.1
    min: 0.005
  lr_cycle_decay:
    distribution: uniform
    max: 1
    min: 0.25
  lr_k_decay:
    distribution: int_uniform
    max: 2
    min: 1
  min_lr:
    distribution: uniform
    max: 2e-06
    min: 2.5e-07
  mixup:
    distribution: uniform
    max: 0.2
    min: 0.05
  mixup_prob:
    distribution: int_uniform
    max: 2
    min: 1
  model_ema_decay:
    distribution: uniform
    max: 0.9999
    min: 0.99
  momentum:
    distribution: uniform
    max: 0.99
    min: 0.5
  patience_epochs:
    distribution: int_uniform
    max: 20
    min: 5
  reprob:
    distribution: uniform
    max: 0.25
    min: 0.1
  sched:
    distribution: categorical
    values:
      - cosine
  seed:
    distribution: int_uniform
    max: 84
    min: 21
  smoothing:
    distribution: uniform
    max: 0.15
    min: 0.05
  vflip:
    distribution: uniform
    max: 0.9
    min: 0.25
  warmup_epochs:
    distribution: int_uniform
    max: 25
    min: 3
  warmup_lr:
    distribution: uniform
    max: 1e-06
    min: 2.5e-07
  weight_decay:
    distribution: uniform
    max: 0.08
    min: 0.025
program: train.py

and terminal output:
![sweep](https://user-images.githubusercontent.com/46447559/228454948-ba868774-154d-4fb4-a23d-565edc2c7989.JPG)
Thank you very much!

