TITLE:
[Feature]: ignore global_step?

LABEL:
feature_request,c:sync,c:tensorboard

STATE:
open

BODY:
### Description

```python
#!/usr/bin/env python
"""main."""
import wandb
from torch.utils.tensorboard.writer import SummaryWriter

model = image_models["mbt2018"](pretrained=True, quality=6)

log_dir = '/output/logs'

name = '5'
wandb.init(project="my-test-project-2", dir=log_dir, name=name, id=name,
           config={"learning_rate": 0.001, "epochs": 100, "batch_size": 128},
           sync_tensorboard=True)

writer = SummaryWriter(log_dir=log_dir)

writer.add_scalars('metrics/loss', {'train': 20, 'val': 100}, 0)
writer.add_scalars('metrics/loss', {'train': 10, 'val':  50}, 1)

# Optional
wandb.finish()
```

```
wandb: Run history:
wandb:                          global_step ▁█
wandb:  logs/metrics_loss_train/global_step ▁█
wandb: logs/metrics_loss_train/metrics/loss █▁
wandb:    logs/metrics_loss_val/global_step ▁█
wandb:   logs/metrics_loss_val/metrics/loss █▁
wandb:
wandb: Run summary:
wandb:                          global_step 1
wandb:  logs/metrics_loss_train/global_step 1
wandb: logs/metrics_loss_train/metrics/loss 10.0
wandb:    logs/metrics_loss_val/global_step 1
wandb:   logs/metrics_loss_val/metrics/loss 50.0
```

Can it ignore uploading any global_step?


### Suggested Solution

```python
wandb.init(sync_tensorboard=True, ignore='.*global_step')
```

### Alternatives

_No response_

### Additional Context

_No response_

