TITLE:
Metric present but marked as <null> (Parallel Coordinates)

LABEL:
stale

STATE:
closed

BODY:
`wandb --version && python --version && uname`

* Weights and Biases version: 0.9.4
* Python version: 3.6.9
* Operating System: Linux (Ubuntu 18.04.2)

### Description

Eventhough I have values for my `accuracy` metric (the graph is not empty), the **Parallel Coordinates** graph doesn't show the final value (all runs are marked as `<null>`).
![image](https://user-images.githubusercontent.com/16095843/88802798-df0ceb00-d1ab-11ea-8c3c-cd643ae223aa.png)

![image](https://user-images.githubusercontent.com/16095843/88802758-cf8da200-d1ab-11ea-8525-1ddeefb90e84.png)


### What I Did

I guess I know where the problem might be because my logs are a little bit strange.
I am building my model in 2 times :
- First, I train an autoencoder, logging `loss` and `val_loss` metrics to Wandb plus an additional `accuracy` which value is 0 (needed by `keras-tuner` library to perform the hyperparameter search) at the end of each epoch.
- Then, I create an anomaly detection model from the autoencoder (determine a threshold and everything) and evaluate its performances on a supervised task which returns an `accuracy` value (and few others metrics, as FalsePositive, ...) that I log to Wandb.

This double logging thing make my last `accuracy` value logged one step after many other metrics (ie, if `loss` and `val_loss` were logged during the first 156 steps, the last `accuracy` value will be on the 157th step).

For information, during the autoencoder's training the `accuracy` value is correctly shown as 0 and get wiped out afterwards.

