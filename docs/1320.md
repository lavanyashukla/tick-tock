TITLE:
Training loss is not being logged for pytorch-lightning version greater 0.8.5

LABEL:
bug

STATE:
closed

BODY:
Hi,
when using wandb with pytorch-lightning I experienced that the training loss is not automatically logged anymore. I tried the versions > 0.8.5. The test loss is still being fetched. Since this problem also affects other logging integrations, e.g. Neptune.ai (verified), I am not sure on which side the logging is failing. 

Tried code:
```python
from pytorch_lightning.loggers import WandbLogger
wandb.init(project="project")
trainer = pl.Trainer(max_epochs=5, logger=wandb_logger, gpus=0, weights_summary='full')
```
Happened to anyone else?

