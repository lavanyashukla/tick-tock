TITLE:
[CLI] Multi-GPU training with wandb

LABEL:
cli,DDP

STATE:
closed

BODY:
**Description**
I am trying to make my Model train on multiple GPU's following[ this blog post](https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html):
I'm not quite sure if i missed something with WandB while moving to Multi-GPU training. Even tough the code reached the point of spawning the processes no logs where printed up to that point. So I am unable to really get to know where that stuff comes from..  

I would be also just happy to know that this is probably not a wandb bug as i didn't find any resources that theres something special to be considered when working on multiple GPU's with pytorch. 

Relevant Code:
```python
    # Initialize a new wandb run
    wandb.init(project='w2v_did', config=did_config, entity='xxxxx',
               name=datetime.now().strftime("w2v_did " + "_%Y%m%d-%H%M%S"))
    config = wandb.config

    # Using more than one GPU
    if torch.cuda.device_count() > 1:
        device_count = torch.cuda.device_count()
        args.world_size = device_count * args.nodes
        args.gpus = device_count
        args.config = config
        os.environ['MASTER_ADDR'] = 'localhost'
        os.environ['MASTER_PORT'] = '8711'
        print("Using:", device_count, "GPUs!")
        mp.spawn(train, nprocs=args.gpus, args=(args,))
```
Stack Trace:
```bash
 File "/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/usr/local/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 179, in start_processes
    process.start()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "/usr/local/lib/python3.9/multiprocessing/context.py", line 284, in _Popen
    return Popen(process_obj)
  File "/usr/local/lib/python3.9/multiprocessing/popen_spawn_posix.py", line 32, in __init__
    super().__init__(process_obj)
  File "/usr/local/lib/python3.9/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "/usr/local/lib/python3.9/multiprocessing/popen_spawn_posix.py", line 47, in _launch
    reduction.dump(process_obj, fp)
  File "/usr/local/lib/python3.9/multiprocessing/reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
  File "/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py", line 151, in __getattr__
    return self.__getitem__(key)
  File "/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py", line 122, in __getitem__
    return self._items[key]
KeyError: '__getstate__'
```

## Edit 
I have to add that this behaviour is not totally consistent sometime my code runs until spawn and than abort with following message:

```
Using: 2 GPUs!

wandb: Waiting for W&B process to finish, PID 609500
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb:
```
To be honest it is not much but help is very much appreciated!

**Environment**
- Python Version: 3.9.2
- Wandb version: 0.10.23


