TITLE:
[CLI] It seems that wanbd make my parallel model fail to backward my loss!?

LABEL:
cli,stale

STATE:
closed

BODY:
**Description**
I've been using wanbd for a long time, but recently when I update my code for parallel GPU training by adding only one single line code:
```
model = DataParallel(mymodel)
```
, there raised a ValueError:
```
Traceback (most recent call last):

  File "D:\Users\*****\*****\main.py", line 175, in <module>
    train_part(config, model, device, train_loader,

  File "D:\Users\*****\*****\fit.py", line 36, in train_part
    loss.backward()

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\torch\tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\torch\autograd\__init__.py", line 145, in backward
    Variable._execution_engine.run_backward(

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\wandb_torch.py", line 398, in backward_hook
    wandb.run.summary["graph_%i" % graph_idx] = graph

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\wandb_summary.py", line 57, in __setitem__
    self.update({key: val})

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\wandb_summary.py", line 79, in update
    self._update(record)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\wandb_summary.py", line 133, in _update
    self._update_callback(record)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\wandb_run.py", line 756, in _summary_update_callback
    self._backend.interface.publish_summary(summary_record)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\interface\interface.py", line 615, in publish_summary
    pb_summary_record = self._make_summary(summary_record)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\interface\interface.py", line 388, in _make_summary
    json_value = self._summary_encode(item.value, path_from_root)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\interface\interface.py", line 351, in _summary_encode
    data_types.val_to_json(

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\data_types.py", line 2134, in val_to_json
    return val.to_json(run)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\data_types.py", line 1280, in to_json
    json_dict = super(Graph, self).to_json(run)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\site-packages\wandb\sdk\data_types.py", line 493, in to_json
    os.path.relpath(self._path, self._run.dir)

  File "D:\Users\*****\Anaconda3\envs\torch18\lib\ntpath.py", line 703, in relpath
    raise ValueError("path is on mount %r, start on mount %r" % (

ValueError: path is on mount 'C:', start on mount 'D:'
```

Where ***** in path is my private content.
I'm sure it is related with wanbd, because when i run a copy of my code without wanbd but with parallel part, there is no problem.

**How to reproduce**
1. Link to a reproducible script we can run to see the bug
2. Describe what we have to do in order to trigger the issue
3. Add a zip file with the run folder 

**Environment**
- OS: Windows server 2012 R2
- Environment: [e.g. Google Colab]
- Python Version: 3.8.8


