TITLE:
[Feature] Logging something from the optimizer state dict

LABEL:
feature_request,c:watch

STATE:
open

BODY:
I'm working on optimizers in PyTorch, and would like to log some buffers in my optimizer. Having something like `wandb.watch` for optimizers would be a great way to understand what's going on during training.
In a PyTorch Optimizer, each parameter `p` has an associated `state` dict; using keys for logging values of this dict for each parameter would be awesome.

Example use:
```wandb.watch_opt(optimizer, keys=['exp_avg', 'step'], modes=['hist', 'value'], log_freq=1000)```

I don't know that Optimizer objects have hooks like `nn.Module` objects do.


