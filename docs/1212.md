TITLE:
Using Wandb Sweep with Skorch Failed: Need Guide

LABEL:
c:sweeps,c:doc

STATE:
open

BODY:
### Description

I tried to use wandb sweep to tune the hyperparameters in skorch and perform the visulization but I didn't get any result.

### What I Did
My code is :  
```
# Load libraries
import wandb  
from skorch.callbacks import WandbLogger  
import torch  
from torch import nn  
import torch.nn.functional as F  

# Set random seed and device
torch.manual_seed(42); # 
torch.cuda.manual_seed(42) #
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Data Preparation 
import numpy as np
from sklearn.datasets import make_classification

X_train, y = make_classification(1000, 20, n_informative=10, random_state=42)
X_train, y = X_train.astype(np.float32), y.astype(np.int64)

X_train.shape, y.shape, y.mean()

# Net define
class ClassifierModule(nn.Module):
    def __init__(
            self,
            num_units=10,
            nonlin=F.relu,
            dropout=0.5,
    ):
        super(ClassifierModule, self).__init__()
        self.num_units = num_units
        self.nonlin = nonlin
        self.dropout = dropout

        self.dense0 = nn.Linear(20, num_units)
        self.nonlin = nonlin
        self.dropout = nn.Dropout(dropout)
        self.dense1 = nn.Linear(num_units, 10)
        self.output = nn.Linear(10, 2)

    def forward(self, X, **kwargs):
        X = self.nonlin(self.dense0(X))
        X = self.dropout(X)
        X = F.relu(self.dense1(X))
        X = F.softmax(self.output(X), dim=-1)
        return X

# Train and tune
import skorch
from skorch import NeuralNetClassifier
from skorch.callbacks import EpochScoring
f1 = EpochScoring(scoring='f1', lower_is_better=False, on_train=False, name = 'valid_f1')


def train():
    wandb_run = wandb.init()
    config = wandb.config

    net = NeuralNetClassifier(
    ClassifierModule,
    max_epochs=10,
    lr=0.1,
    callbacks = [f1,WandbLogger(wandb_run)],
    train_split = skorch.dataset.CVSplit(5,stratified=True,random_state =42),
    device=device,  # uncomment this to train with CUDA
    )

    net.fit(X_train, y)

sweep_config = {
    'method': 'grid', # or 'grid' or 'random'
    'metric': {
        'name': 'accuracy',
        'goal': 'maximize'
    },
    'parameters':{
        'max_epochs': {
            'values':[10,15,20]
        }
    }
}

sweep_id = wandb.sweep(sweep_config,entity='utunex',project='test')
wandb.agent(sweep_id,train)
```
### Problem:
This code didn't display anything to wandb.

### Please help me on:
1. This is my first time to combine wandb and skorch and I do have no experience, please help check where the problem is in my code;  
2. I guess the problem may lie at the 'metric' item in sweep_config and I'm realy confused about how to set this item in skorch; the official documentation says:
> Specify the metric to optimize. This metric should be __logged explicitly to W&B by your training script__. using wandb.log({"val_loss" : valid_loss})  

This is where I feel confused. In the skorch part in my code, I used f1_score and give it a name as :valid_f1, so should I set thee metric as 'f1' or 'valid_f1'? and how to explicitly log it to wandb? I have used the wandblogger which 

> automatically log best trained model, all metrics from your netâ€™s history, model topology and computer resources to Weights & Biases after each epoch. 

Isn't it enough?
In summary, I hope to know where is the mistake in my code and how to set the metric.

Thank you.

