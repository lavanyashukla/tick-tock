TITLE:
[Q] Why does the artifact download use threads (multiprocessing.dummy) instead of processes?

LABEL:
c:artifacts

STATE:
open

BODY:
I have large datasets of audio files (500+GB) that is stored in S3.
Currently, my dataset in W&B is just a manifest file (JSON lines) with a reference to the audio file name and its label.
I download the files based on the audio file name from S3 using `boto3` and `multiprocessing.Pool` which takes ~10-15 min. when using an EC2 instance w/ 96 cores/processes in the same region as my S3 bucket.

I would like to store references to these files in W&B instead and leave the downloading logic to W&B, however, I am worried this will result in a significant slowdown since [downloading uses `multiprocessing.dummy.Pool`](https://github.com/wandb/client/blob/2721dfda8888adc5f104f72a60d8daf8b14ce45e/wandb/apis/public.py#L3887) which is thread based and hard capped to 32 threads.

Is it possible to modify this somehow to speed up downloads or does `multiprocessing.Pool` interfere with W&B internals somehow?


