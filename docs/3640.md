TITLE:
[Q] Gradients graphs gone once freezing layers

LABEL:
c:watch

STATE:
open

BODY:
Hi, I'm tracking gradients along training and I'll freeze some layers of my network (when a callback funciton is triggered) by:

```
for param in model.parameters():
     param.requires_grad = False
```

Before this operation, everything was logged correctly, once this operation done, all those graphs tracking the gradients of frozen layers are disappeared on the dashboard.

**Expected**: keeps the graphs there even `param.requires_grad = False` after a while, so I could have known how well the frozen part is trained before freezing.

My wandb version: 0.12.16



