TITLE:
[App][Python Public API]: Can't delete subdirectory with many files

LABEL:
app

STATE:
open

BODY:
### Current Behavior

I accidentally saved and uploaded ~1'000'000 files in a wandb run. The Web App allows to free storage at [wandb.ai/usage](url).  Since the Web App can only index 10'000 files at once, it is not possible to delete more than 10'000 files at once.

In particular, if all files are stored within a subdirectory of a specific run, this leads to unexpected behavior:
1. In the project overview, the storage of my run is shown to be at 70 GB. 
2. When inspecting the rundirectory, all files and subdirectories sum up to only 4 GB. 
3. Deleting the subdirectory takes 30secs and on first glance doesn't seem to change anything: the subdirectory is still there and has the same size.
4. After some time, the total storage indicator drops and it becomes clear that 4 GB of files were deleted from the subdirectory. 

Deleting a subdirectory containing many files should be an easy process but is currently very unintuitive and tedious.

### Expected Behavior

In [wandb.ai/usage](url), deleting a subdirectory should delete the entire subdirectory and not only the first 10'000 files. Or at least some information about what is happening with further explanation could be given. 

### Steps To Reproduce

0. Save and upload many files into a subdirectory of a wandb run and add some files which you want to keep.
1. Go to [wandb.ai/usage](url)
2. Click on the run and try to delete the subdirectory.
3. Observe that only the first 10'000 files are silently deleted without a more information. 

### Screenshots

_No response_

### Environment

OS: Windows 10

Browsers: Chrome

### Additional Context

One solution could be to simply inform users that only 10'000 files can be deleted at once and that the [Python file export API ](url) should be used instead. This, however, is also not trivial since the wandb api currently doesn't seem to have explicit semantics for handling subdirectories of rundirectories, as discussed here https://github.com/wandb/wandb/issues/3923 & https://github.com/wandb/wandb/pull/3924.

NaÃ¯vely iterating all files and deleting them after checking the path is very slow and takes a lot of memory. I hacked together a workaround which deletes files in batches but is only efficient if most files are deleted and only a few are skipped. Maybe a  proper `wandb.apis.public.Directory` class with specialized `.download()` and `.delete()` methods would generally be beneficial?


```python
import wandb
from tqdm import tqdm
from wandb.apis.public import gql
api = wandb.Api()

# copied from https://github.com/wandb/wandb/blob/a339333b3ee93864daf416f04c1501186dffac5c/wandb/apis/public.py#L2388
MUTATION_DELETE_FILES = gql(
    """
mutation deleteFiles($files: [ID!]!) {
    deleteFiles(input: {
        files: $files
    }) {
        success
    }
}
"""
)

# configuration
entity = 'username'
project = 'projectname'
rundir = 'rundir'
subdir = 'subdir'
batchsize = 500 # delete files in batches of 500

# get run and files
run = api.run(f'{entity}/{project}/runs/{rundir}')
files = run.files()

# compute number of batches
n_files = len(files)
n_batches = n_files // batchsize + 1

# iterate batches and delete batchwise
skipped_files = 0
batches_pbar = tqdm(range(n_batches))
for batch in batches_pbar:

    ids, files = [], run.files()
    for index in range(skipped_files, skipped_files + batchsize):
        if index >= len(files): # if batchsize is larger than remaining files
            break

        if files[index].name.startswith(subdir): # filter by filename
            ids.append(files[index].id)
        else:
            skipped_files += 1

    batches_pbar.set_postfix({'skipped':skipped_files, 'remaining':len(files)})
    if len(ids) > 0:
        run.client.execute(MUTATION_DELETE_FILES, variable_values={"files": ids})
```








