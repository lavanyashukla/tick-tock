TITLE:
Issue with individual metric steps with sync_tensorboard

LABEL:
c:misc

STATE:
closed

BODY:
`wandb --version && python --version && uname`

* Weights and Biases version: 0.8.32
* Python version: 3.6.7
* Operating System: Linux

### Description

Each metric has a separate counter in tensorboard. A possible use case example:
```
    # in the training loop, after each batch or log-freq
    writer.add_scalar('Loss/Train', train_loss, epoch * len(trainloader) + batch_idx)

....
writer.add_scalar('Loss/Valid', valid_loss, epoch) # after each epoch
```

However, when using `sync_tensorboard`, that counter isn't being used & a max of all counters is being used, perhaps that becomes the global counter. Also, there's only that 1 single counter wandb's dashboard & the plots become super difficult to understand. 



I created a demo showing this [here](https://app.wandb.ai/tshrjn/demo-steps/workspace?workspace=user-tshrjn).


### What I Did
The code is as follows:
```
import wandb
from torch.utils.tensorboard import SummaryWriter

wandb.init(project="demo-steps", sync_tensorboard=True)
writer = SummaryWriter()

bs, epochs = 10, 100

for epoch in range(epochs):
    for batch_idx in range(bs):
        writer.add_scalar('batch', batch_idx, epoch * bs + batch_idx)
    writer.add_scalar('epoch', epoch, epoch)
```

Looking at the code above & then graphs, it'd be immediately clear that there's some issue with the x-axis steps for epochs.


Am I missing something?

