TITLE:
Parameters are not logged when model is watched with log='all'

LABEL:
cli

STATE:
closed

BODY:
**Description**
This is the same bug as in #1471, which was closed without resolution of the problem.

When using `logger.watch(model, log='all', log_freq=1)`, the gradients are logged, but the parameters are not.

I am also using pytorch lightning, as was the author of that issue, so perhaps that's related.

**How to reproduce**

I don't have a clean way to reproduce. When I tried to reproduce the problem in this wandb lightning colab: http://wandb.me/lit-colab, everything worked as expected. I'm not sure what's different about my setup.

**Environment**
- ubuntu 18.04
- wandb version: '0.10.33'
- pytorch lightning version: '1.3.7post0`
- pytorch version: '1.9.0+cu102'



