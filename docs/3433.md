TITLE:
[App]: Internal wandb error: file data was not synced

LABEL:
app

STATE:
closed

BODY:
### Current Behavior

Model training stops at an arbitrary point when the process is synced to the online app. Processes run fine when done 'offline'. The error has occurred at various times, eg ~1750 epochs, ~2000 epochs, ~4000 epochs. The error message is clear but the cause is not; why would a local log file suddenly become unavailable?

```
<Normal logging...>
epoch: 1500, loss:  2.184e+06, time:   934.3, log_vars: 14.7473, -0.3149
epoch: 1750, loss:  9.470e+05, time:  1091.9, log_vars: 14.4531, -0.3113
Thread SenderThread:
Traceback (most recent call last):
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\internal_util.py", line 54, in run
    self._run()
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\internal_util.py", line 105, in _run
    self._process(record)
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\internal.py", line 312, in _process
    self._sm.send(record)
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\sender.py", line 237, in send
    send_handler(record)
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\sender.py", line 830, in send_summary
    self._update_summary()
  File "C:\Users\xxxx\AppData\Local\Programs\Python\Python39\lib\site-packages\wandb\sdk\internal\sender.py", line 842, in _update_summary
    with open(summary_path, "w") as f:PermissionError: [Errno 13] Permission denied: 'C:\\Users\\Iblah\\blah\\blah\\wandb\\run-20220324_140524-2zt53myz\\files\\wandb-summary.json'
wandb: ERROR Internal wandb error: file data was not synced
```

And then tracebacks from a particular log command:
`run.log({"train/loss":loss.item()**.5})`
leading to 
`Exception: The wandb backend process has shutdown`

### Expected Behavior

Expectation is for model training to continue through the prescribed number of epochs, with pretty standard logging statements. Instead it breaks at arbitrary times.

### Steps To Reproduce

_No response_

### Screenshots

_No response_

### Environment

OS: Windows

Browsers: MS Edge

Version: MS Edge Version 99.0.1150.46 (Official build) (64-bit)


### Additional Context

Earlier I'd run up to 10k epochs with pretty much the same code. I changed the loss function and the models a bit, but not sure why it would affect logging, in particular why anything I did in the model building code would affect access to a log file on my local file system.

