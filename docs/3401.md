TITLE:
[App]: Agent bug? File not found error

LABEL:
app

STATE:
open

BODY:
### Current Behavior

I tried it on kaggle and colab

When using the attached notebook I get the following error:
[notebook](https://www.kaggle.com/code/wojtekddl/license-plate-w-b)


```
wandb: Agent Starting Run: 9uvr1lj3 with config:
wandb: 	batch_size: 64
wandb: 	dropout: 0.2
wandb: 	dropout_lstm: 0.1
wandb: 	epochs: 8
wandb: 	hidden_size: 32
wandb: 	linear_output: 64
wandb: 	models: PlateLUX_2GRU
wandb: 	optimizer: RMSprop
wandb: 	scheduler: ReduceLROnPlateau
wandb: Currently logged in as: wualas (use `wandb login --relogin` to force relogin)
Tracking run with wandb version 0.12.11
Run data is saved locally in /kaggle/working/wandb/run-20220318_082708-9uvr1lj3
Syncing run winter-sweep-1 to Weights & Biases (docs)
Sweep page: https://wandb.ai/wualas/pytorch-sweeps-rejestracje_last/sweeps/7ioy5yu1

Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
Synced winter-sweep-1: https://wandb.ai/wualas/pytorch-sweeps-rejestracje_last/runs/9uvr1lj3
Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
Find logs at: ./wandb/run-20220318_082708-9uvr1lj3/logs
Run 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')
wandb: ERROR Run 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')
`
```

### Expected Behavior

Firstly I upgrade
`!pip install wandb --upgrade`

`wandb.login()`

define sweep
```
sweep_config = {
    'method' : 'random',
}
metric = {
    'name' : 'EXACTacc',
    'goal' : 'maximize'
}
sweep_config['metric'] = metric
parameters_dict = {
    'epochs': {
        'values': [5, 6, 8]
    },
    'batch_size': {
        'values': [8, 16, 32, 64, 128]
    },
    'dropout': {
        'values': [0.2, 0.4, 0.5]
    },
    'dropout_lstm': {
        'values': [0.1, 0.25, 0.4]
    },
    'linear_output': {
        'values': [32, 64, 128]
    },
    'hidden_size': {
        'values': [16, 32, 64]
    },
    'optimizer': {
        'values': ['adam', 'sgd', 'RMSprop'] # z scheduler
    },
    'scheduler': {
        'values': ['ReduceLROnPlateau', 'ExponentialLR', 'CyclicLR - exp_range'] # z scheduler
    },
    'models': {
        'values': ['PlateLUX_default', 'PlateLUX_2GRU', 'PlateLUX_1GRU', 'PlateLUX_BIGGEST'] # z scheduler
    }
}
sweep_config['parameters'] = parameters_dict

```
`sweep_id = wandb.sweep(sweep_config, project="pytorch-sweeps-rejestracje_last")`
```
train_function:


def train(config=None):
    with wandb.init(config=config):
        config = wandb.config
        df = pd.read_csv('/content/OCRdataset/annotations_CRNN.csv')
        df['filename'] = '/content/OCRdataset/images/' + df['filename'].astype(str)
        image_files = df['filename'].tolist()
        targets_orig = df['label'].tolist()
        targets = [[c for c in x] for x in targets_orig]
        targets_flat = [c for clist in targets for c in clist]

        lbl_enc = preprocessing.LabelEncoder()
        lbl_enc.fit(targets_flat)
        targets_enc = [lbl_enc.transform(x) for x in targets]
        targets_enc = np.array(targets_enc)
        targets_enc = targets_enc + 1

        (
        train_imgs,
        test_imgs,
        train_targets,
        test_targets,
        _,
        test_targets_orig,
        ) = model_selection.train_test_split(
        image_files, targets_enc, targets_orig, test_size=0.1, random_state=42
        )
        num_chars=len(lbl_enc.classes_)
        train_loader, test_loader = build_loader(train_imgs, train_targets, test_imgs, test_targets, config.batch_size)
        model = build_network(config.models, num_chars, config.linear_output, config.hidden_size, config.dropout, config.dropout_lstm)
        optimizer = build_optimizer(model, config.optimizer)
        scheduler = build_scheduler(optimizer, config.scheduler)

        #train_loss_tab = []
        #test_loss_tab = []
        #accuracy_tab = []
        #best_test_loss = 100000000000000
        for epoch in range(config.epochs):
            train_loss = train_fn(model, train_loader, optimizer)
            valid_preds, test_loss = eval_fn(model, test_loader)
            valid_captcha_preds = []
            for vp in valid_preds:
                current_preds = decode_predictions(vp, lbl_enc)
                valid_captcha_preds.extend(current_preds)
            combined = list(zip(test_targets_orig, valid_captcha_preds))
            print(combined)
            test_dup_rem = [remove_duplicates(c) for c in test_targets_orig]
            accuracy = metrics.accuracy_score(test_dup_rem, valid_captcha_preds)
            print(
              f"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}"
            )
            exloss = calculate_EXACTloss(combined)
            scheduler.step(test_loss)
            #torch.save(model.state_dict(), "/content/epoch_save/EPOCH_SAVER_CRNN_state_dict3{}.pt".format(epoch))
            # dopisac zapisywanie kazdego modelu
            #train_loss_tab.append(train_loss)
            #test_loss_tab.append(test_loss)
            #accuracy_tab.append(accuracy)
            print("zapisuje")
            wandb.log({'epoch': epoch, 'loss_test': test_loss, 'loss_train': train_loss, 'accuracy': accuracy, 'EXACTacc' : exloss})

```

and run:

`wandb.agent(sweep_id, train, count=1)`

Is there an error how Iâ€™m using wandb or is this a bug?

### Environment

* Weights and Biases version: 0.12.11
* Python version: 3.7.12


