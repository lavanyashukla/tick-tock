TITLE:
[Q] Logging multiple models' performances when they depend on each other

LABEL:
c:misc

STATE:
closed

BODY:
So I'm running experiments with probabilistic neural networks, where I first train a 'prior' neural network and then use this prior to train a 'posterior' neural network(whose performance is dependent on the prior). As such, I have 2 neural networks whose performances depend on sets of overlapping parameters, which I would like to evaluate as 2 separate networks but as a single Experiment. 

I've currently got weights and biases logging the trainining/testing process of both networks to a single Experiment, but this leads to a problem where W&B interprets it as data coming from the same network and both losses get graphed on the same line.

I've come up with kind of a hacky fix to get the graphs separate by logging the 'prior' network's data with 'epoch' being the x-axis, and logging the 'posterior' network's data with 'Epoch' being the x-axis, which lets me generate plots for losses, error, etc. for both within the same Experiment.

I'm wondering if there is a better or easier way to do this than the way that I've figured out. I'm planning on running hyperparameter search in this experiment setting and I'm unsure if my fix will continue to work. Any help/advice would be appreciated!

