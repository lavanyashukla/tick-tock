TITLE:
[Q] Intentionally Crashing (For Factorized Sweep Grid Search)

LABEL:
c:sweeps

STATE:
open

BODY:
Hi there,

My question is this: from within a python script being run from within a wandb sweep, I'd like to be able to send a signal to the server saying that the program temporarily "crashed the agent", _but continue to run the agent on different runs in this same sweep_. The reason for this is kind of involved and I think not entirely necessary for you to understand, but if you'd like here it is.

I'm trying to create a factorized grid search.  For example, imagine I want to try to test the following grid:
```
batch_size: [10,15]
optimizer: ['adam', 'adamw', 'sgd']
weight_decay: [.3, .4]
lr: [0.0, 0.1, 0.2]
```

I understand how to turn that into a config file and run a wandb sweep over it.

But what if I want to run a grid search, and _not use all elements of the grid_ – e.g. I don't care about sgd with weight decay 0 vs .1 vs .2 – I'm not using weight decay when I use sgd.  And likewise with the adam optimizers, I don't care about the learning rate – I've fixed it. Really, the grid then becomes something like this:
```
batch_size: [10,15]
subset1:
    optimizer: ['adam', 'adamw']
    weight_decay: [.3, .4]
subset2:
    optimizer: ['sgd']
    lr: [0.0, 0.1, 0.2]
```

I've written a script that will allow me to do this with wandb, but I'm stuck on one problem.  I can figure out whether the given run is one that I should run or should ignore, but I'm not sure what to do next.  Right now, I'm exiting with an error (assert False).  But the problem is that in big sweeps, then it takes time to figure out which programs actually exited with an error (which I'd want to see), and which were "fake" runs that immediately exited.

This is a convoluted way of doing it, I know.  It'd be best if wandb had a solution to this.  If so, would you mind telling me what it is?  If not, would you tell me how I can "crash" my program from within it.  If I can do that, then I can filter my visualizations based on crashed runs and see "true" failed runs. Or is there another workaround you'd recommend?

Thank you for making a great tool!

