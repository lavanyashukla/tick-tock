{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjwn6YBJiSin4qxquX7bsf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanyashukla/tick-tock/blob/main/LWM_1_1_Tick_Tock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "4i82ncQQx5NJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtmahQp9cBCV"
      },
      "outputs": [],
      "source": [
        "!pip install openai -qq\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lavanyashukla/tick-tock.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8IK_HCJbYcq",
        "outputId": "82344e38-a5eb-460c-8cb9-ce8a4d1426ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'tick-tock' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "input_file = open('tick-tock/data/support_tickets.json')\n",
        "data = json.load(input_file)"
      ],
      "metadata": {
        "id": "wFoGv3BHbjPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "- Navigate to the \"Secrets\" pane from the left navigation bar\n",
        "- Add the OPENAI_API_KEY name and value\n",
        "- Turn on the toggle of \"Notebook access\""
      ],
      "metadata": {
        "id": "bPyiIh2wcHQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=userdata.get('OPENAI_API_KEY')\n",
        ")\n",
        "\n",
        "# get the tags\n",
        "file_path = 'tick-tock/data/tags.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    tags = [line.strip() for line in file]\n",
        "print(tags)\n",
        "\n",
        "# get the priorities\n",
        "file_path = 'tick-tock/data/priorities.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    priorities = [line.strip() for line in file]\n",
        "print(priorities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niaOe97XbmAU",
        "outputId": "ab3f84fa-0077-467c-8823-b4cf2ad27707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zopim_offline_message', 'zopim_chat_missed', 'zopim_chat_ended', 'zopim_chat', 'zendesk', 'yolov5', 'xgboost', 'workspace_2', 'workspace', 'workplace_2', 'workplace', 'workaround', 'windows', 'weights__biases', 'webinar', 'weave', 'watch', 'wandblogger', 'wandbdb', 'wandb_offline', 'waiting_on_info', 'vulnerability', 'videos', 'video', 'verification', 'vega-plots', 'vega', 'username', 'user-management', 'user_management_2', 'user_management__move_projects_2', 'user_management__move_projects', 'user_management___delete_user_2', 'user_management___delete_user', 'user_management', 'upgrade', 'updated_jira', 'update_jira', 'unresponsive_user_2', 'unresponsive_user', 'ui', 'type_question', 'type_product_feedback', 'type_feature_request', 'type_bug', 'trial', 'tracked_hours', 'ticket_roulette_chat', 'testing_bump', 'test', 'tensorflow', 'tensorboard_2', 'tensorboard', 'teams', 'team-settings', 'team-management', 'team_management_2', 'team_management', 'team', 'tags', 'tables_component', 'tables_2', 'tables', 'table', 'system-metrics', 'system_metrics_2', 'system_metrics', 'sync', 'sydney_test', 'sweeps_2', 'sweeps', 'support', 'summary-graph', 'subscriptions__upgrade_', 'subscriptions__downgrade_', 'subscriptions__cancel_', 'story', 'store_true', 'storage_2', 'storage', 'stale_request_2', 'stale_request', 'stale', 'sso', 'slurm', 'slack-alerts', 'sla_warning', 'sklearn', 'setup-bug', 'service-account', 'self_service_customer', 'security', 'search', 'score', 'scatter_plot', 'sample', 'sales-intercom-chat', 'sales', 'sagemaker', 'runsets', 'runs-table', 'runs_2', 'runs', 'run-table', 'run-sets', 'run-deletion', 'run-comparer', 'run_comparer', 'roboserg', 'resuming-runs', 'resuming_2', 'resuming', 'request', 'reproduced', 'reports_2', 'reports', 'redacted_content', 'rate-limiting', 'rate_limits_2', 'rate_limits', 'rate', 'quote', 'question', 'qualcomm', 'pytorch-lightning', 'pytorch_2', 'pytorch', 'publishing', 'prospect', 'projects_2', 'projects', 'production_monitoring', 'productboard', 'product-feedback', 'product_feedback_2', 'product_feedback', 'product_csat', 'produce_feedback_2', 'produce_feedback', 'pricing', 'power_user', 'point-cloud', 'png-export', 'plots', 'plotly', 'phishing_risk_zendesk', 'personal', 'performance_2', 'performance', 'pendo_nps', 'pending_6_days', 'password_reset', 'pass_to_sales_2', 'pass_to_sales', 'pass_to_csm_2', 'pass_to_csm', 'partnership', 'parcoords', 'paper-author', 'panel', 'paid-team-customer', 'p3', 'p2', 'p1', 'p0', 'p', 'outage', 'other_2', 'other__non-technical', 'other', 'org-management', 'org_management_2', 'org_management', 'onboarding', 'on-prem', 'nps_score_2', 'nps_score', 'nps_followup_zapier', 'nps_follow_up', 'nps', 'not-yet-reproduced', 'not-training-models', 'non-support', 'non_support_2', 'no_tags_added', 'no_sla', 'no_second_tag_added', 'no_notifications', 'no_csat', 'nice', 'network_2', 'network_', 'netron', 'negative_nps', 'needs_ticket', 'needs_follow_up', 'navigation', 'multithreading', 'multiprocessing_2', 'multiprocessing', 'moviepy', 'move-runs', 'move-projects', 'move_projects', 'mobile-app', 'mlw_component', 'ml-question', 'metadata', 'media-panel', 'media_panel_2', 'media_panel', 'media', 'marketing_site', 'many_runs', 'mail', 'luis', 'logs_2', 'logs', 'logging', 'local_license_request', 'local_2', 'local__gcp', 'local__azure', 'local__aws', 'local', 'linux', 'linters', 'line-plot', 'limiting', 'lightning', 'license', 'legend', 'lead', 'knowledge_base', 'kind', 'keras_2', 'keras', 'kaggle', 'jupyter_2', 'jupyter', 'jira_update', 'jira_escalated', 'internal', 'intern', 'intercom_migration', 'intercom', 'integration', 'import', 'images', 'image-uploading', 'hydra', 'histogram', 'hiring', 'heat-map', 'halp', 'guest', 'grouping', 'graphcore', 'gradients', 'gradient_dissent', 'gpu', 'good_satisfaction', 'github_exalate', 'github', 'gdpr', 'frontend', 'fr_form', 'forum', 'filters', 'filtering', 'files', 'feedback', 'feature-request', 'feature_request', 'feature', 'fastapi', 'fastai', 'failed', 'facebook', 'export', 'examples', 'escalated_jira', 'error-messaging', 'error', 'environment-setup', 'enterprise_customer', 'enterprise', 'enhancement', 'duplicate_email', 'dsviz', 'downtime_2', 'downtime', 'dont_bump', 'documentation', 'docs_2', 'docs_1', 'docs__web_app', 'docs__client', 'docs', 'design', 'demo-request', 'delete-account', 'delete_user', 'delete_account', 'delete', 'deal-blocker', 'ddp', 'dataset-management', 'data-limits', 'dashboard', 'customer-churn', 'customer', 'custom-charts', 'custom', 'csat-score', 'csat', 'cs-reviewed', 'created_from_slack', 'crashed_run_2', 'crashed_run', 'crash_notif', 'core_fix', 'core_archived', 'connectivity_2', 'connectivity', 'config', 'conda', 'compute_hours', 'component_local', 'component_cli', 'component_artifacts', 'command_line', 'colab_2', 'colab', 'code-tab', 'code_saving', 'cluster', 'cloud_services', 'closed_by_merge', 'cling', 'client__sagemaker_2', 'client__sagemaker', 'client__public_api_2', 'client__public_api', 'client__other', 'client__launch', 'client__integrations__yolov5', 'client__integrations__xgboost', 'client__integrations__tensorboard', 'client__integrations__spacy', 'client__integrations__sklearn', 'client__integrations__sagemaker', 'client__integrations__pytorch', 'client__integrations__openai', 'client__integrations__keras', 'client__integrations__jupyter_notebooks', 'client__integrations__hugging_face', 'client__integrations__fast.ai', 'client__environment_variables', 'client__authentication_2', 'client__authentication', 'client__artifacts_2', 'client__artifacts', 'client___pytorch_lightning', 'cli_2', 'cli__integrations__other', 'cli', 'class', 'citing', 'checkpoints', 'charts_histogram_2', 'charts_histogram', 'charts_2', 'charts__grouping_2', 'charts__grouping', 'charts__custom_charts_2', 'charts__custom_charts', 'charts', 'change-username', 'change-mail', 'change-email', 'change', 'cancel_account', 'c:sweeps', 'c:jupyter', 'c:framework', 'c:doc', 'c:cling', 'c:artifacts', 'c:api', 'bump2', 'bump1', 'bug_2', 'bug', 'brave', 'best_value', 'best_practices', 'benchmark', 'bad-nps', 'bad_satisfaction', 'bad', 'backend', 'auto-assigned', 'auto_nps', 'auto_followup', 'authors', 'authentication', 'auth0', 'assigned_tr', 'asking-about-teams', 'asking-about-local', 'artifacts_2', 'artifacts', 'app__weave', 'app__sweeps_2', 'app__sweeps', 'app__runs_table', 'app__other', 'app__multiple_emails_', 'app__model_registry', 'app__login', 'app__export', 'app__artifacts_2', 'app__artifacts', 'app', 'api_2', 'api', 'advice', 'admin-tools', 'admin__user_management__change_entity_name_2', 'admin__user_management__change_entity_name', 'admin__subscriptions__invoices_', 'admin', 'add-seat', 'add_stale_note', 'add_cc_note', 'ad_board_fix', 'account', 'academic', 'acad', '8hr_sla_unassigned', '6day_no_update', '5day_expired', '3hr_sla_unassigned', '3hr_sla_assigned', '3hr_sla', '3day_no_update', '3day_expired', '2minutepapers', '1hr_sla', '.yaml']\n",
            "['low', 'high', 'urgent', 'normal', 'None']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make a filtered dataset"
      ],
      "metadata": {
        "id": "PLe3r81Hx9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten all tags from all dictionaries into a single list\n",
        "all_tags = [tag for d in data for tag in d.get('tags', [])]\n",
        "\n",
        "# Use Counter to count occurrences of each tag\n",
        "tag_counts = Counter(all_tags)\n",
        "\n",
        "# List of specific tags you're interested in\n",
        "specific_tags = [\"charts\", \"sweeps\", \"reports\", \"tables\"]\n",
        "\n",
        "# Filter the tag_counts for specific tags and create a sorted list of tuples (tag, count)\n",
        "sorted_specific_tag_counts = sorted(\n",
        "    [(tag, tag_counts.get(tag, 0)) for tag in specific_tags],\n",
        "    key=lambda x: x[1], reverse=True\n",
        ")\n",
        "\n",
        "# Convert to DataFrame for nicer display\n",
        "df = pd.DataFrame(sorted_specific_tag_counts, columns=['Tag', 'Count'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghSwXSSIoB0U",
        "outputId": "4c1b715e-1df3-4cdb-98d4-3c49c3bc64ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Tag  Count\n",
            "0   charts    903\n",
            "1   sweeps    678\n",
            "2  reports    310\n",
            "3   tables    280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering process\n",
        "desired_tags = [\"cli\", \"charts\", \"backend\", \"sweeps\", \"reports\", \"tables\"]\n",
        "filtered_data = [d for d in data if any(tag in d.get('tags', []) for tag in desired_tags)]\n",
        "\n",
        "print(len(filtered_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "759PSyvMlJL6",
        "outputId": "2ea73abd-7777-4815-879d-1b0ec0841367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the data\n",
        "show_elem = 4\n",
        "print(json.dumps(filtered_data[show_elem], indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWg_Xuece4-_",
        "outputId": "208d6a18-d302-49c7-b532-2326662a0341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"description\": \"Hi, I've noticed that when I run a training script through `wandb agent` , a fatal exception in the code is not printed out to the console. While when I run the same code directly with `python train.py` I see the exception in the command output. Looks like if the agent was suppressing the exception printout to the console. Have you heard about something like that?\",\n",
            "    \"raw_subject\": \"[SDK] wandb agent fatal exception not printed\",\n",
            "    \"subject\": \"[SDK] wandb agent fatal exception not printed\",\n",
            "    \"priority\": \"urgent\",\n",
            "    \"problem_id\": null,\n",
            "    \"tags\": [\n",
            "        \"component_cli\",\n",
            "        \"enterprise_customer\",\n",
            "        \"halp\",\n",
            "        \"p0\",\n",
            "        \"question\",\n",
            "        \"sweeps\"\n",
            "    ],\n",
            "    \"id\": 36380,\n",
            "    \"360043868271\": \"question\",\n",
            "    \"360042457771\": [\n",
            "        \"enterprise_customer\"\n",
            "    ],\n",
            "    \"360042775872\": [\n",
            "        \"component_cli\"\n",
            "    ],\n",
            "    \"360042457751\": \"sweeps\",\n",
            "    \"360044019192\": null,\n",
            "    \"360041678631\": \"https://weightsandbiases.slack.com/archives/C01L79NKX5L/p1669025253633279?thread_ts=1669007664.253479&cid=C01L79NKX5L\",\n",
            "    \"360041794452\": null,\n",
            "    \"4419373106452\": null,\n",
            "    \"4419370133012\": null,\n",
            "    \"4419373051540\": null,\n",
            "    \"4419370299284\": null,\n",
            "    \"4419380461716\": null,\n",
            "    \"4417243931028\": false,\n",
            "    \"4419380411796\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count, score_priority, score_tags = 0, 0, 0\n",
        "acc = {}"
      ],
      "metadata": {
        "id": "yzY-EL9te5P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering"
      ],
      "metadata": {
        "id": "aIULZF-HyB8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "f07dqQqCy8zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OILxp2VKu6Nn",
        "outputId": "ad864ed4-56d6-43f5-86de-2224b42c42ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_prompt():\n",
        "  count, score_tags = 0, 0\n",
        "  for element in filtered_data[100:110]:\n",
        "      # print(element)\n",
        "      ticket_text = element['description']\n",
        "\n",
        "      # Prompt – Classify Class\n",
        "      prompt = f\"\"\"\n",
        "      Classify the text delimited by triple backticks into one of the following classes.\n",
        "      Classes: {desired_tags}\n",
        "      Text: ```{ticket_text}```\n",
        "      Class: \"\"\"\n",
        "\n",
        "      response = get_completion(prompt)\n",
        "\n",
        "      print(\"Prediction: \"+response)\n",
        "\n",
        "      if(response in element['tags']):\n",
        "          score_tags += 1\n",
        "          print(\"Correct\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      else:\n",
        "          print(\"Incorrect\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      count += 1\n",
        "      print()\n",
        "\n",
        "  print(\"__________________\")\n",
        "  print(f\"Priority Accuracy: {score_tags/count}\")\n",
        "  return score_tags/count\n",
        "acc['basic_prompt'] = basic_prompt()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnqL1a1EbHM3",
        "outputId": "fc883266-1bfc-4044-b757-a0d42edb057d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: N/A\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: backend\n",
            "Correct\n",
            "['backend']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['tables']\n",
            "\n",
            "Prediction: backend\n",
            "Incorrect\n",
            "['cli']\n",
            "\n",
            "Prediction: ['backend']\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: ['sweeps']\n",
            "Incorrect\n",
            "['sweeps']\n",
            "\n",
            "Prediction: ['backend']\n",
            "Incorrect\n",
            "['reports']\n",
            "\n",
            "Prediction: charts\n",
            "Correct\n",
            "['charts']\n",
            "\n",
            "Prediction: sweeps\n",
            "Correct\n",
            "['sweeps']\n",
            "\n",
            "Prediction: ['backend']\n",
            "Incorrect\n",
            "['charts', 'cli']\n",
            "\n",
            "__________________\n",
            "Priority Accuracy: 0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_5_examples():\n",
        "  count, score_tags = 0, 0\n",
        "  for element in filtered_data[100:110]:\n",
        "      # print(element)\n",
        "      ticket_text = element['description']\n",
        "      examples = \"\".join([\n",
        "                     f\"Text: ```{element['description']}```\\nClass: {next((tag for tag in desired_tags if tag in element['tags']), 'No matching tag')}\\n\"\n",
        "                     for i, element in enumerate(filtered_data[:5])\n",
        "                 ])\n",
        "\n",
        "      # Prompt – Classify Class\n",
        "      prompt = f\"\"\"\n",
        "      Classify the text delimited by triple backticks into one of the following classes.\n",
        "      Classes: {desired_tags}\n",
        "\n",
        "      {examples}\n",
        "\n",
        "      Text: ```{ticket_text}```\n",
        "      Class: \"\"\"\n",
        "      response = get_completion(prompt)\n",
        "\n",
        "      # print(\"Prompt: \"+prompt)\n",
        "      print(\"Prediction: \"+response)\n",
        "\n",
        "      if(response in element['tags']):\n",
        "          score_tags += 1\n",
        "          print(\"Correct\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      else:\n",
        "          print(\"Incorrect\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      count += 1\n",
        "      print()\n",
        "\n",
        "  print(\"__________________\")\n",
        "  print(f\"Priority Accuracy: {score_tags/count}\")\n",
        "  return score_tags/count\n",
        "acc['add_5_examples'] = add_5_examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVZp113EEid7",
        "outputId": "6122ef18-6ea3-4fee-f374-f6dc8260f9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: N/A\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: backend\n",
            "Correct\n",
            "['backend']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['tables']\n",
            "\n",
            "Prediction: backend\n",
            "Incorrect\n",
            "['cli']\n",
            "\n",
            "Prediction: N/A\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['sweeps']\n",
            "\n",
            "Prediction: reports\n",
            "Correct\n",
            "['reports']\n",
            "\n",
            "Prediction: charts\n",
            "Correct\n",
            "['charts']\n",
            "\n",
            "Prediction: sweeps\n",
            "Correct\n",
            "['sweeps']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['charts', 'cli']\n",
            "\n",
            "__________________\n",
            "Priority Accuracy: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_100_examples():\n",
        "  count, score_tags = 0, 0\n",
        "  for element in filtered_data[100:110]:\n",
        "      # print(element)\n",
        "      ticket_text = element['description']\n",
        "      examples = \"\".join([\n",
        "                     f\"Text: ```{element['description']}```\\nClass: {next((tag for tag in desired_tags if tag in element['tags']), 'No matching tag')}\\n\"\n",
        "                     for i, element in enumerate(filtered_data[:5])\n",
        "                 ])\n",
        "\n",
        "      # Prompt – Classify Class\n",
        "      prompt = f\"\"\"\n",
        "      Classify the text delimited by triple backticks into one of the following classes.\n",
        "      Classes: {desired_tags}\n",
        "\n",
        "      {examples}\n",
        "\n",
        "      Text: ```{ticket_text}```\n",
        "      Class: \"\"\"\n",
        "      response = get_completion(prompt)\n",
        "\n",
        "      # print(\"Prompt: \"+prompt)\n",
        "      print(\"Prediction: \"+response)\n",
        "\n",
        "      if(response in element['tags']):\n",
        "          score_tags += 1\n",
        "          print(\"Correct\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      else:\n",
        "          print(\"Incorrect\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      count += 1\n",
        "      print()\n",
        "\n",
        "  print(\"__________________\")\n",
        "  print(f\"Priority Accuracy: {score_tags/count}\")\n",
        "  return score_tags/count\n",
        "acc['add_100_examples'] = add_100_examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3m4_y9WE3Rx",
        "outputId": "692e5ada-56c9-4ac0-da2b-85e04e1ba0b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: N/A\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: backend\n",
            "Correct\n",
            "['backend']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['tables']\n",
            "\n",
            "Prediction: backend\n",
            "Incorrect\n",
            "['cli']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['sweeps']\n",
            "\n",
            "Prediction: reports\n",
            "Correct\n",
            "['reports']\n",
            "\n",
            "Prediction: charts\n",
            "Correct\n",
            "['charts']\n",
            "\n",
            "Prediction: sweeps\n",
            "Correct\n",
            "['sweeps']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['charts', 'cli']\n",
            "\n",
            "__________________\n",
            "Priority Accuracy: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_classes():\n",
        "  count, score_tags = 0, 0\n",
        "  for element in filtered_data[100:110]:\n",
        "      # print(element)\n",
        "      ticket_text = element['description']\n",
        "      examples = \"\".join([\n",
        "                     f\"Text: ```{element['description']}```\\nClass: {next((tag for tag in desired_tags if tag in element['tags']), 'No matching tag')}\\n\"\n",
        "                     for i, element in enumerate(filtered_data[:5])\n",
        "                 ])\n",
        "\n",
        "      # Prompt – Classify Class\n",
        "      prompt = f\"\"\"\n",
        "      Given the following description for each class:\n",
        "      charts: Log rich plots in a W&B workspace to visualize model performace over time. Log images, video, audio, bar charts, histograms and more.\n",
        "      sweeps: Use W&B Sweeps to automate hyperparameter search and visualize rich, interactive experiment tracking. Pick from popular search methods such as Bayesian, grid search, and random to search the hyperparameter space. Scale and parallelize sweep across one or more machines.\n",
        "      reports: Use W&B Reports to organize Runs, embed and automate visualizations, describe your findings, and share updates with collaborators. Easily export your report as a LaTeX zip file or convert the file to PDF.\n",
        "      tables: Log a table in an artifact for each meaningful step of training to analyze model performance over training time\n",
        "\n",
        "      Classify the text delimited by triple backticks into one of the following classes.\n",
        "      Classes: {desired_tags}\n",
        "\n",
        "      {examples}\n",
        "\n",
        "      Text: ```{ticket_text}```\n",
        "      Class: \"\"\"\n",
        "      response = get_completion(prompt)\n",
        "\n",
        "      # print(\"Prompt: \"+prompt)\n",
        "      print(\"Prediction: \"+response)\n",
        "\n",
        "      if(response in element['tags']):\n",
        "          score_tags += 1\n",
        "          print(\"Correct\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      else:\n",
        "          print(\"Incorrect\")\n",
        "          print([tag for tag in element['tags'] if tag in desired_tags])\n",
        "      count += 1\n",
        "      print()\n",
        "\n",
        "  print(\"__________________\")\n",
        "  print(f\"Priority Accuracy: {score_tags/count}\")\n",
        "  return score_tags/count\n",
        "acc['describe_classes'] = describe_classes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75FRFDQQJvl5",
        "outputId": "1568d2a6-e829-4604-83f6-25513518cb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: cli\n",
            "Incorrect\n",
            "['backend']\n",
            "\n",
            "Prediction: backend\n",
            "Correct\n",
            "['backend']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['tables']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['cli']\n",
            "\n",
            "Prediction: backend\n",
            "Correct\n",
            "['backend']\n",
            "\n",
            "Prediction: sweeps\n",
            "Correct\n",
            "['sweeps']\n",
            "\n",
            "Prediction: charts\n",
            "Incorrect\n",
            "['reports']\n",
            "\n",
            "Prediction: charts\n",
            "Correct\n",
            "['charts']\n",
            "\n",
            "Prediction: sweeps\n",
            "Correct\n",
            "['sweeps']\n",
            "\n",
            "Prediction: reports\n",
            "Incorrect\n",
            "['charts', 'cli']\n",
            "\n",
            "__________________\n",
            "Priority Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(list(acc.items()), columns=['Prompt', 'Accuracy']).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdp-rWd9Kp-K",
        "outputId": "06ee18c6-9034-4e9a-c17d-f067ecff6280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Prompt  Accuracy\n",
            "    basic_prompt       0.3\n",
            "  add_5_examples       0.4\n",
            "add_100_examples       0.4\n",
            "describe_classes       0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxmEJCQ_Napx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}