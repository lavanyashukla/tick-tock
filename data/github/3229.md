TITLE:
[CLI] [App] Multiple tensorboard issues.

LABEL:
cli

STATE:
closed

BODY:
**Description**
The tensorboard integration has a number of issues.

## Issue 1: `global_step` reset.

Related to #1997, when running the following code with the latest `wandb=0.12.10`, nothing gets logged as shown in this [tracked experiment](https://wandb.ai/costa-huang/cleanRL/runs/17g4fl38)

```python
import numpy as np
import random
import time
from torch.utils.tensorboard import SummaryWriter
import wandb

if __name__ == "__main__":
    # setup the environment
    experiment_name = f"wandb=={wandb.__version__}__{int(time.time())}"
    run = wandb.init(
        project="cleanRL",
        entity=None,
        sync_tensorboard=True,
        name=experiment_name,
        save_code=True,
    )
    writer = SummaryWriter(f"runs/{experiment_name}")
    for global_step in range(100):
        writer.add_scalar("loss1", np.random.rand(1)[0], global_step)
    for global_step in range(100):
        writer.add_scalar("loss2", np.random.rand(1)[0], global_step)
```

![image](https://user-images.githubusercontent.com/5555347/152884157-7cb2c621-937c-4f5f-a179-7c5fe953d378.png)

Doing it slightly differently using `wandb.tensorboard.patch(save=False)` also results in [undesired results](https://wandb.ai/costa-huang/cleanRL/runs/39afcf46), where `loss2` is displayed incorrectly 

```diff
 import numpy as np
 import random
 import time
 from torch.utils.tensorboard import SummaryWriter
 import wandb
 
 if __name__ == "__main__":
     # setup the environment
     experiment_name = f"wandb=={wandb.__version__}__{int(time.time())}"
     run = wandb.init(
         project="cleanRL",
         entity=None,
-        sync_tensorboard=True,
         name=experiment_name,
         save_code=True,
     )
+    wandb.tensorboard.patch(save=False)
     writer = SummaryWriter(f"runs/{experiment_name}")
     for global_step in range(100):
         writer.add_scalar("loss1", np.random.rand(1)[0], global_step)
     for global_step in range(100):
         writer.add_scalar("loss2", np.random.rand(1)[0], global_step)
```

![image](https://user-images.githubusercontent.com/5555347/152884225-2f032ad1-7b19-4dc8-8d49-0c56cd5fc9ac.png)




#1997's suggestion fo adding `wandb.tensorboard.patch(root_logdir=f'runs/{experiment_name}')` which fixes the issue as shown in this [tracked experiment](https://wandb.ai/costa-huang/cleanRL/runs/2skd9qyi), but it feels a bit hacky... 

```diff
 import numpy as np
 import random
 import time
 from torch.utils.tensorboard import SummaryWriter
 import wandb
 
 if __name__ == "__main__":
     # setup the environment
     experiment_name = f"wandb=={wandb.__version__}__{int(time.time())}"
+    wandb.tensorboard.patch(root_logdir=f'runs/{experiment_name}') 
     run = wandb.init(
         project="cleanRL",
         entity=None,
-        sync_tensorboard=True,
         name=experiment_name,
         save_code=True,
     )
     writer = SummaryWriter(f"runs/{experiment_name}")
     for global_step in range(100):
         writer.add_scalar("loss1", np.random.rand(1)[0], global_step)
     for global_step in range(100):
         writer.add_scalar("loss2", np.random.rand(1)[0], global_step)
```
![image](https://user-images.githubusercontent.com/5555347/152884004-2269c813-2403-44e4-aaeb-6e25c0de3da1.png)


## Issue 2: missing data when displayed using `global_step` as x-axis

The successful experiment that incorporated the approach from #1997 still has a minor issue: in the dashboard, we don't see the datapoint in `loss1` when `x=99` (we can only see up to `x=98`). See the video below for a demo.

https://user-images.githubusercontent.com/5555347/152885010-c669da4f-28e0-4eed-8db7-2fac65a3117a.mp4

While this may appear like a minor issue, I run into a similar issue like this at a much larger scale. As shown in the video below, in [this experiment](https://wandb.ai/gym-microrts/gym-microrts/runs/13tizcke?workspace=user-costa-huang) I was missing data that are available when using `Step` as the x-axis. Clearly, the last `charts/trueskill` summary is 37.323, but I could not visualize this data even when zooming into the chart that used the `global_step` as the x-axis.

https://user-images.githubusercontent.com/5555347/152885830-c2b39863-01eb-4522-a7df-cc0e799ab212.mp4

## Issue 3: data not logged in Windows with `sync_tensorboard=True`

A number of my collaborators who use Windows have tried to log experiments with `wandb.init(..., sync_tensorboard=True)` but no data was logged, which looks like

![image](https://user-images.githubusercontent.com/5555347/152887128-c8a15110-c8e5-4f44-b303-ef331fca1d14.png)


See https://github.com/vwxyzjn/gym-microrts/pull/25 and https://github.com/vwxyzjn/vectorized-value-methods/pull/7. What worked for them on Windows is to replace `sync_tensorboard=True` with `wandb.tensorboard.patch(save=False)`. 


## Issue 4: Tensorboard page in the app crashes:

https://wandb.ai/costa-huang/cleanRL/runs/2skd9qyi/tensorboard?workspace=user-costa-huang

See the following video

https://user-images.githubusercontent.com/5555347/152886944-326807b2-9336-4cbd-81f4-05066812fde0.mp4



