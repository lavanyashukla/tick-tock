TITLE:
[Q] Visualizing results using wandb when running distributed training in AWS Sagemaker

LABEL:
c:flexible-env,c:sagemaker

STATE:
open

BODY:
I'm running training in Sagemaker - 
```
from sagemaker.huggingface import HuggingFace

# configuration for running training on smdistributed Model Parallel
mpi_options = {
    "enabled" : True,
    "processes_per_host" : 8,
}
smp_options = {
    "enabled":True,
    "parameters": {
        "microbatches": 4,
        "placement_strategy": "spread",
        "pipeline": "interleaved",
        "optimize": "speed",
        "partitions": 4,
        "ddp": True,
    }
}

distribution={
    "smdistributed": {"modelparallel": smp_options},
    "mpi": mpi_options
}

# hyperparameters, which are passed into the training job
hyperparameters={'epochs': 4,
                 'train_batch_size': 4,
                 'eval_batch_size': 8,
                 'learning_rate': 5e-5,
                 'pretrained_model':'allenai/longformer-base-4096'
                 }
huggingface_estimator = HuggingFace(entry_point='train.py',
                            source_dir='./scripts',
                            instance_type="ml.p3.2xlarge",
                            instance_count=1,
                            role=role,
                            transformers_version='4.12',
                            pytorch_version='1.9',
                            py_version='py38',
                            distribution= distribution,
                            hyperparameters = hyperparameters)
```

and in my script `train.py` I'm initiating wandb :
  ```
  wandb.login(key = <key>)
  wandb.init(entity=<"">, project=<"">, config=args, allow_val_change=True,  group=wandb.util.generate_id())
```

this throws an error 
`ErrorMessage ":FileExistsError: [Errno 17] File exists: '/opt/ml/code/wandb/run-20220718_162530-huggingface-pytorch-training-2022-07-18-16-18-11-461-algo-1/run-huggingface-pytorch-training-2022-07-18-16-18-11-461-algo-1.wandb'`

Setting a group for all runs isn't working here, is this because I'm logging in to wandb in every distributed run?


