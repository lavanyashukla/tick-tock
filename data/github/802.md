TITLE:
[tune/WandbLogger] Multi-trial runs are displayed incorrectly in the ui

LABEL:
question,c:sweeps,stale

STATE:
open

BODY:
- Weights and Biases version: 0.8.22
- Python version: 3.7.5
- Operating System: Darwin

I'm actually not sure if this is a bug or if I'm assuming something wrong or using wandb incorrectly.

### Description
When running multiple trials per run using tune, the results come out incorrectly when viewing them at the wandb web ui. Wandb somehow interprets the data from individual trials belonging together, such that the data is concatenated along the x-axis. For example, see the images below:

The view from wandbui for the results ran with the script below:
![image](https://user-images.githubusercontent.com/2308543/73137307-ababa100-404e-11ea-9fba-d3e8889bd9bb.png)
I would expect to see the x-axis values ranging from 0 to 9 (due to `stop={"training_iteration": 10}` in the config). Instead, there are 6 * 9 = 54 steps. The custom visualization view also thinks that none of the values are not monotonically increasing, even though some of them should be:
![image](https://user-images.githubusercontent.com/2308543/73137342-edd4e280-404e-11ea-940c-b293cb5ff13c.png)

Here's the (expected) output [viskit](https://github.com/vitchyr/viskit) gives us:
![image](https://user-images.githubusercontent.com/2308543/73137356-0b09b100-404f-11ea-8898-8527941553c9.png)
In this figure, we see 15 trials and x-axis steps from 0 to 9, as expected.


### What I Did
```python
import random
import  time

import tensorflow as tf
import tensorflow_probability as tfp
import ray
from ray import tune
from wandb.ray import WandbLogger


class ExperimentRunner(tune.Trainable):
    def _setup(self, variant):
        self.timestep = 0

    def _train(self):
        self.timestep += 1
        v = tf.tanh(float(self.timestep) / self.config.get("width", 1)).numpy()
        v *= self.config.get("height", 1)

        time.sleep(tf.random.uniform((), minval=0.1, maxval=2.0))

        return {"episode_reward_mean": v}


def main():
    tune.run(
        ExperimentRunner,
        resources_per_trial={'cpu': 2},
        loggers=[tune.logger.UnifiedLogger, WandbLogger],
        num_samples=5,
        stop={"training_iteration": 10},
        config={
            "width": tune.grid_search([10, 20, 30]),
            "height": tune.sample_from(lambda spec: int(100 * random.random())),
            'monitor': True,
            'env_config': {"wandb": {"project": "my-project-name"}},
        },
        local_dir='/tmp/wandb-test')


if __name__ == '__main__':
    main()
```

