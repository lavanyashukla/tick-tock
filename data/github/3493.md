TITLE:
[Q] Lots of new empty sweeps created

LABEL:
c:misc

STATE:
closed

BODY:
Seeing this in the terminal:
```
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/2v8il4ij
Create sweep with ID: e3iewba6
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/e3iewba6
Create sweep with ID: 61e91obd
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/61e91obd
Create sweep with ID: w41a3yej
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/w41a3yej
Create sweep with ID: cerop646
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/cerop646
  0%|                                                                                                                                                                                                                                           | 1/4101 [00:18<21:26:26, 18.83s/it]Create sweep with ID: 3z1dlr18
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/3z1dlr18
Create sweep with ID: qa9vxkbt
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/qa9vxkbt
Create sweep with ID: 1uaic891
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/1uaic891
Create sweep with ID: yflplztn
Sweep URL: https://wandb.ai/sergeyf/SAD_sweep_roberta_v2022_04_07/sweeps/yflplztn
```

All of these are empty. Here is my complete code:

```
import torch

torch.multiprocessing.set_sharing_strategy("file_system")

import os

os.environ["WANDB_WATCH"] = "false"
os.environ["TOKENIZERS_PARALLELISM"] = "false"
from multiprocess import freeze_support
import pandas as pd
import numpy as np
from simpletransformers.classification import ClassificationModel, ClassificationArgs
import wandb
import gc
from sklearn.metrics import f1_score

# load data and split randomly into train/val/test
df = pd.read_excel("SAD_v1.xlsx")[["sentence", "top_label"]]
df.columns = ["text", "labels"]
labels = list(df["labels"].unique())
num_labels = len(labels)
df = df.sample(frac=1, random_state=42, replace=False)
n_train = int(0.6 * len(df))
n_val = int(0.2 * len(df))
n_test = len(df) - n_val - n_train
split = np.array(["train"] * n_train + ["val"] * n_val + ["test"] * n_test)

# WANDB
wandb_project_name = "SAD_sweep_roberta_v2022_04_07"

sweep_config = {
    "name": "roberta-base",
    "method": "grid",  # bayes, grid, random
    "metric": {"name": "f1_score", "goal": "maximize"},
    "parameters": {
        "learning_rate": {"values": [5e-6, 5e-5, 4e-5]},
        "num_train_epochs": {"values": [2, 3]},
    },
}

sweep_id = wandb.sweep(sweep_config, project=wandb_project_name)


def f1(y_true, y_pred):
    return f1_score(y_true, y_pred, average="weighted")


def train():
    wandb.init(project=wandb_project_name)
    model_args = ClassificationArgs()
    model_args.scheduler = "cosine_schedule_with_warmup"
    model_args.num_train_epochs = wandb.config.num_train_epochs
    model_args.learning_rate = wandb.config.learning_rate
    model_args.evaluate_during_training = False
    # model_args.evaluate_during_training_steps = 1000
    # model_args.evaluate_during_training_verbose = True
    model_args.reprocess_input_data = True
    model_args.overwrite_output_dir = True
    model_args.manual_seed = 4
    model_args.train_batch_size = 32
    model_args.eval_batch_size = 128
    model_args.labels_list = labels
    model_args.wandb_project = wandb_project_name

    # "roberta", "roberta-large"
    # "roberta", "roberta-base"
    model = ClassificationModel(
        "roberta", "roberta-base", args=model_args, use_cuda=True, num_labels=num_labels, sweep_config=wandb.config
    )

    model.train_model(df[split == "train"], f1_score=f1)

    # eval
    result_vl, model_outputs_vl, wrong_predictions_vl = model.eval_model(df[split == "val"], f1_score=f1)

    wandb.log({"F1": result_vl["f1_score"], "MCC": result_vl["mcc"]})
    del model
    del model_args
    gc.collect()
    torch.cuda.empty_cache()
    wandb.join()
[SAD_v1.xlsx](https://github.com/wandb/client/files/8446567/SAD_v1.xlsx)


if __name__ == "__main__":
    freeze_support()
    wandb.agent(sweep_id, train)
```

Dataset is attached if you'd like to reproduce exactly.

