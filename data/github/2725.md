TITLE:
[App] Images fail to show when using Pytorch Lightning LearningRateMonitor

LABEL:
app

STATE:
closed

BODY:
**Describe the bug**
Running the code below has a very odd issue. When using the LearningRateMonitor, images fail to be shown in the dashboard. https://wandb.ai/danielgordon10/mnist_example_bug?workspace=user-danielgordon10
<img width="1395" alt="Screen Shot 2021-10-04 at 10 34 26 AM" src="https://user-images.githubusercontent.com/7245472/135897847-301a5888-f90e-405a-ae49-8932000bd1a6.png">

However the images still exist in the media tab https://wandb.ai/danielgordon10/mnist_example_bug/runs/vf70rtja/files/media/images



**To Reproduce**
Steps to reproduce the behavior:
Minimal code example
```python
import argparse
import os
from argparse import ArgumentError
from typing import Any, Dict, Optional, Union

import numpy as np
import pytorch_lightning as pl
import torch
import torch.nn
import torch.optim
import wandb
from pytorch_lightning import LightningModule, Trainer
from pytorch_lightning.callbacks import Callback, LearningRateMonitor
from pytorch_lightning.core.datamodule import LightningDataModule
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.loggers.base import rank_zero_experiment
from pytorch_lightning.loggers.tensorboard import TensorBoardLogger
from pytorch_lightning.utilities import rank_zero_only
from torch import nn
from torch.nn import functional as F
from torch.utils.data import DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
from torchvision.datasets import MNIST


class MNISTModel(LightningModule):
    def __init__(self, hidden_size: int = 64, learning_rate: float = 2e-4):
        super(MNISTModel, self).__init__()
        self.save_hyperparameters()

        # Set our init args as class attributes
        self.hidden_size = hidden_size
        self.learning_rate = learning_rate

        # Hardcode some dataset specific attributes
        self.num_classes = 10

        self.dims = (1, 28, 28)
        channels, width, height = self.dims
        self.example_input_array = torch.zeros((2, channels, height, width), dtype=torch.float32)

        # Define LeNet model
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(),
            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(),
        )
        # Split just because
        self.mlp = nn.Sequential(
            nn.Flatten(),
            nn.Linear(16 * 5 * 5, 120),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(120, 84),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(84, self.num_classes),
        )

    def forward(self, x: torch.Tensor):
        """Standard forward like PyTorch"""
        x = self.conv(x)
        x = self.mlp(x)
        return F.log_softmax(x, dim=1)

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 20)
        return [optimizer], [scheduler]

    def training_step(self, batch: Any, batch_idx: int) -> Union[torch.Tensor, Dict[str, Any]]:
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return {"loss": loss}

    def training_step_end(self, step_outputs):
        loss = step_outputs["loss"]
        return loss

    def validation_step(self, batch: Any, batch_idx: int):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)
        return {"val_loss": loss}

    # Here we just reuse the validation logic for testing
    def test_step(self, batch, batch_idx):
        return self.validation_step(batch, batch_idx)


class MNISTDataModule(LightningDataModule):
    def __init__(
        self,
        batch_size: int = 32,
        data_dir: str = "/data/mnist",
    ):
        self.batch_size = batch_size
        self.data_dir = data_dir
        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        super(MNISTDataModule, self).__init__()

    def prepare_data(self):
        # download
        MNIST(self.data_dir, train=True, download=True)
        MNIST(self.data_dir, train=False, download=True)

    def setup(self, stage=None):
        # Assign train/val datasets for use in dataloaders
        if stage == "fit" or stage is None:
            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)
            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])

        # Assign test dataset for use in dataloader(s)
        if stage == "test" or stage is None:
            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)

    def train_dataloader(self):
        return DataLoader(
            self.mnist_train,
            batch_size=self.batch_size,
            num_workers=8,
        )

    def val_dataloader(self):
        return DataLoader(
            self.mnist_val,
            batch_size=self.batch_size,
            num_workers=8,
        )

    def test_dataloader(self):
        return DataLoader(
            self.mnist_test,
            batch_size=self.batch_size,
            num_workers=8,
        )


def kernels_to_image(data, padsize: int = 1) -> np.ndarray:
    """Turns a set convolutional kernels into an image of nicely tiled filters.

    Args:
        data (npt.NPT_TYPE): Kernels as (N x C x H x W). For example (64 x 3 x 7 x 7) for 64 7x7 kernels on RGB data.
        padsize (int, optional): How much visual padding to add between kernels. Defaults to 1 pixel.

    Returns:
        np.ndarray: Image of the first 3 kernel channels in a tiled/mosaic layout.
    """
    assert data.ndim == 4, f"data.ndim was {data.ndim}"
    # Move channels to end.
    data_np = np.asarray(data, dtype=np.float32)
    data_np = np.ascontiguousarray(np.transpose(data_np, (0, 2, 3, 1)))

    # Bump contrast by min/max normalizing each kernel. Do computations in-place.
    column_data = np.reshape(data_np, (data_np.shape[0], -1))
    column_data -= np.min(column_data, axis=1, keepdims=True)
    column_data /= np.max(column_data, axis=1, keepdims=True)

    kernels_per_row = int(np.ceil(np.sqrt(data_np.shape[0])))
    padding = ((0, kernels_per_row ** 2 - data_np.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),)
    data_np = np.pad(data_np, padding, mode="constant", constant_values=0)
    # Tile the filters into an image
    data_np = data_np.reshape(kernels_per_row, kernels_per_row, *data_np.shape[1:])
    data_np = data_np.swapaxes(1, 2)
    data_np = data_np.reshape(
        data_np.shape[0] * data_np.shape[1], data_np.shape[2] * data_np.shape[3], *data_np.shape[4:]
    )
    # Add padding around edge
    data_np = np.pad(data_np, ((padsize, 0), (padsize, 0), (0, 0)), mode="constant", constant_values=0)
    return (data_np * 255).astype(np.uint8)


class CustomTensorboardWriter(SummaryWriter):
    def conv_network_summary(self, network: torch.nn.Module, step: Optional[int] = None):
        """Log the weights of a convnet and draw the kernels as images."""
        for ii, (name, val) in enumerate(network.state_dict().items()):
            val = val.detach().cpu().numpy()
            name = "layer_%03d_" % ii + name
            if len(val.shape) == 4:
                self.conv_weight_summaries(val, step, name)

    def conv_weight_summaries(self, tensor, step: Optional[int] = None, scope=""):
        """Log a weight summary for all the weights/biases in a network."""
        tensor_np = np.asarray(tensor)
        # Useful stats for weights and the kernel images.
        scope = os.path.join("conv_summaries", scope + "_kernels")
        tensor_shape = tensor_np.shape
        if not (tensor_shape[0] == 1 and tensor_shape[1] == 1):
            summary_image = kernels_to_image(tensor_np[:, :3, :, :])
            if summary_image.shape[2] == 1:
                summary_image = np.tile(summary_image, [1, 1, 3])
            self.image_summary(scope, summary_image, step)

    def image_summary(self, tag: str, images, step: Optional[int] = None, max_size=1000):
        """Log a list of images."""
        images_np = np.asarray(images, dtype=np.uint8)
        if len(images_np.shape) == 2:
            images_np = np.tile(images_np[:, :, np.newaxis], (1, 1, 3))
        self.add_image(f"{tag}", images_np, step, dataformats="HWC")


class CustomTensorBoardLogger(TensorBoardLogger):
    @property
    @rank_zero_experiment
    def experiment(self) -> SummaryWriter:
        if self._experiment is not None:
            return self._experiment

        assert rank_zero_only.rank == 0, "tried to init log dirs in non global_rank=0"
        if self.root_dir:
            self._fs.makedirs(self.root_dir, exist_ok=True)
        self._experiment = CustomTensorboardWriter(log_dir=self.log_dir, **self._kwargs)
        return self._experiment


class LoggingCallback(Callback):
    def __init__(self) -> None:
        pass

    def get_tensorboard_logger(self, pl_module) -> CustomTensorBoardLogger:
        for logger in pl_module.logger:
            if isinstance(logger, CustomTensorBoardLogger):
                return logger
        raise ArgumentError(pl_module, "No CustomTensorBoardLogger found")

    def on_train_epoch_start(self, trainer: Trainer, pl_module: LightningModule) -> None:
        assert pl_module.logger is not None
        logger = self.get_tensorboard_logger(pl_module)
        logger.experiment.conv_network_summary(pl_module, pl_module.global_step)


# Training code
def train():
    parser = argparse.ArgumentParser(description="Run training for MNIST using Pytorch Lightning")
    parser.add_argument("--output_dir", type=str, default="/data/mnist_logs")
    parser.add_argument("--max_epochs", type=int, default=3)
    parser.add_argument("--batch_size", type=int, default=256)
    args = parser.parse_args()
    model = MNISTModel()
    datamodule = MNISTDataModule(batch_size=args.batch_size)
    tensorboard_logger = CustomTensorBoardLogger(
        os.path.join(args.output_dir, "tensorboard"), name="logs", log_graph=True, default_hp_metric=False
    )

    wandb.init(
        project="mnist_example_bug",
        config=args.__dict__,
        sync_tensorboard=True,
        name=os.path.basename(tensorboard_logger.log_dir),
    )
    wandb_logger = WandbLogger(
        log_model=True,
    )
    wandb_logger.watch(model)

    trainer = pl.Trainer.from_argparse_args(
        args,
        logger=[tensorboard_logger, wandb_logger],
        callbacks=[LoggingCallback(), LearningRateMonitor(logging_interval="step")],
    )
    trainer.fit(model, datamodule=datamodule)


if __name__ == "__main__":
    train()
```

