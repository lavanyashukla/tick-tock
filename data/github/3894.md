TITLE:
[Q] How to make sure wandb.log() updates wandb before moving onto new code? 

LABEL:
cli

STATE:
closed

BODY:
I'm having a related issue to #3244. I'm able to use best_loss = sweep.best_run().summary_metrics['loss'] to find the lowest value of loss (float value) in a given sweep. The problem is that I believe wandb.log() is not updating wandb fast enough before sweep.best_run().summary_metrics['loss'] is executed. This leads to a KeyError('loss') exception on the first epoch. I've tried using the commit=true parameter but this doesn't do the trick.

Is there a way to make wandb.log() update wandb before moving onto new code? Here is my code:

` for epoch in range(config.epochs):

        avg_loss = train_epoch(network, trainloader, optimizer, scheduler)

        # log loss
        wandb.log({"loss": avg_loss, "epoch": epoch}, commit=True)

        # update best_loss for next call to checkpoint_saver
        best_loss = sweep.best_run().summary_metrics['loss'] 

        # save weights of current best epoch
        if avg_loss <= best_loss:
          checkpoint_saver(network, avg_loss)`
Thanks

