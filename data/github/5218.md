TITLE:
[Feature]: watch activations & update value, besides weights and gradients

LABEL:
feature_request,c:watch

STATE:
open

BODY:
### Description

I want to track the activations of my model. I also think it's more useful to watch the update size rather than gradients. 

### Suggested Solution

Just extend `wandb.watch` to have `activations, update_size`. Latter might need to hook the optimizer too. 

### Alternatives

implementing it myself with .log? But I'd need to loop through my model or the activations stored by the pytorch graph...

### Additional Context

I feel activations predict better loss divergence than weights, since activations are the ones used in the backward pass for backprop. 

