TITLE:
Inconsistent Logging Values when using explicit id

LABEL:
cli

STATE:
closed

BODY:
### Describe the bug

<!--- Description of the issue below  -->
When I use the same id and project name for `wandb.init` repeatedly after deleting local wandb folder and project on the web, there seems to be unexpected behaviour. Essentially, I am writing training loss every batch and writing validation log at the end of every epoch. But when this error occurs, validation log is recorded between epochs.
The link for the validation log: https://api.wandb.ai/links/kurttutan-mert/x7xlkbg4

A few strange observations:
- When I do not specify the id, the error does not occur at all
- When I change naming of metric key `val/epoch` -> `val/val_epoch`, the error does not occur at all
<!--- A minimal code snippet between the quotes below  -->
- When I change the id for run, it does not occur either. I also tested the same run id and project name pair on different machines, the error still persists.
```python
# main.py
import torchvision

from torch.utils.data import DataLoader
import wandb

import torchvision.transforms as transforms


def get_dataset_cifar10():
    transform_list = [transforms.ToTensor()]

    train_transformer = transforms.Compose(transform_list)

    dataset = torchvision.datasets.CIFAR10(
        root='./data/cifar10', train=True,
        download=True, transform=train_transformer
    )
    return dataset

def get_cifar10_dataloader(
    batch_size,
    shuffle,
    num_workers,
):  

    cifar10_dataset = get_dataset_cifar10()
    return DataLoader(
        dataset=cifar10_dataset,
        batch_size=batch_size, 
        shuffle=shuffle,
        num_workers=num_workers,
    )


def train():
    workers = 8
    project_name = "pytorch-project"
    run_id = "historical123"
    train_data = {"batch_size": 64, "shuffle": True}

    train_loader = get_cifar10_dataloader(
        **train_data,
        num_workers=workers,
    )

    logger = wandb.init(
        id=run_id,
        project=project_name,
    )

    n_steps_per_epoch = len(train_loader)
    for epoch in range(5):
        for i, (train_x, train_y) in enumerate(train_loader):
            metric_dict = {"train/epoch": epoch}
            if i+1 < n_steps_per_epoch:
                logger.log(
                     metric_dict
                )
        metric_dict["val/epoch"] = epoch
        logger.log(metric_dict)

    logger.finish()


if __name__ == "__main__":
    train()
```

<!--- A full traceback of the exception in the quotes below -->
```shell
python3 main.py

```

This code is executable as I tested on different machines. But if the bug is related to the state of the account, this may not be reproducible.



System logs: 

``` shell
wandb: Tracking run with wandb version 0.13.9
wandb: Run data is saved locally in /content/wandb/run-20230201_182715-historical123
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run historical123
wandb: ⭐️View project at https://wandb.ai/kurttutan-mert/pytorch-project
wandb: 🚀View run at https://wandb.ai/kurttutan-mert/pytorch-project/runs/historical123
wandb: Waiting for W&B process to finish... (success).
wandb:
wandb: Run history:
wandb: train/epoch ▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆████████
wandb: val/epoch ▁▃▅▆█
wandb:
wandb: Run summary:
wandb: train/epoch 4
wandb: val/epoch 4
wandb:
wandb: 🚀View run historical123 at: https://wandb.ai/kurttutan-mert/pytorch-project/run
s/historical123
wandb: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 
```

If you check the value of val/epoch on system logs  is increasing monotonically as it should whereas the result on the web is not.

### Additional Files

_No response_

### Environment

WandB version: 0.13.9

OS: Ubuntu 22.04, 20.04, 18.04

Python version: 3.10, and 3.9

Versions of relevant libraries: torch 3.13 (even though torch did not play any role other than iterating through its dataset)

### Additional Context

_No response_

