TITLE:
Logging Error

LABEL:
cli,stale

STATE:
closed

BODY:
**Description**
I am facing a problem that causes logs to not being uploaded, a logging error appears at the start of training script, then everything continues just fine.
**Wandb features**
I am using pytorch lightning, wandb, and hydra

**How to reproduce**
My project is quite messy and large and it's hard to reproduce, but I think the cause of it may be related to  hydra DictConfig not supported properly,  something related to the Arabic language, or the way pl_module saves the hparams and hand it to wandb. 

This is how I call wanb:
```
    wandb = instantiate(cfg.logger.params)
    wandb.watch(pl_model.model)
```

This is the error message that I get, it contain the content of my DictConfig:
```
--- Logging error ---
Traceback (most recent call last):
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\logging\__init__.py", line 1084, in emit     stream.write(msg + self.terminator)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\encodings\cp1252.py", line 19, in encode     return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode character '\u0623' in position 6583: character maps to <undefined>
Call stack:
  File "train.py", line 242, in <module>     cli_main()
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\main.py", line 33, in decorated_main     _run_hydra(
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\_internal\utils.py", line 364, in _run_hydra     run_and_report(
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\_internal\utils.py", line 212, in run_and_report     return func()
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\_internal\utils.py", line 365, in <lambda>     lambda: hydra.run(
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\_internal\hydra.py", line 109, in run     return run_job(
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\hydra\core\utils.py", line 129, in run_job     ret.return_value = task_function(task_cfg)
  File "train.py", line 148, in cli_main     trainer.fit(model, datamodule=dm)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 510, in fit     results = self.accelerator_backend.train()
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\pytorch_lightning\accelerators\accelerator.py", line 56, in train     self.trainer.setup_trainer(self.trainer.model)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\pytorch_lightning\trainer\trainer.py", line 442, in setup_trainer     self.logger.log_hyperparams(ref_model.hparams_initial)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\pytorch_lightning\utilities\distributed.py", line 40, in wrapped_fn     return fn(*args, **kwargs)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\pytorch_lightning\loggers\wandb.py", line 170, in log_hyperparams     self.experiment.config.update(params, allow_val_change=True)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\wandb\sdk\wandb_config.py", line 172, in update     self._callback(data=sanitized)
  File "C:\Users\Mohammed\.conda\envs\dl_env\lib\site-packages\wandb\sdk\wandb_run.py", line 663, in _config_callback     logger.info("config_cb %s %s %s", key, val, data)
Message: 'config_cb %s %s %s' Arguments: (None, None, {'scheduler/name': 'step_lr', 'scheduler/interval': 'epoch', 'scheduler/reduce_on_plateau': False, 'scheduler/_target_': 'torch.optim.lr_scheduler.StepLR', 'scheduler/params/step_size': 1, 'scheduler/params/gamma': 0.965, 'dataset/name': 'ahcd', 'dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'dataset/train_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'dataset/train_dataset/path': '../../../AHCD/Characters/X_train_split.csv', 'dataset/train_dataset/label_path': '../../../AHCD/Characters/y_train_split.csv', 'dataset/val_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'dataset/val_dataset/path': '../../../AHCD/Characters/X_val.csv', 'dataset/val_dataset/label_path': '../../../AHCD/Characters/y_val.csv', 'dataset/test_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'dataset/test_dataset/path': '../../../AHCD/Characters/X_test.csv', 'dataset/test_dataset/label_path': '../../../AHCD/Characters/y_test.csv', 'model/name': 'res_cnn_cls', 'model/_target_': 'src.models.models.ResidualCNNClassification', 'model/params/n_classes': 28, 'model/params/dims': 32, 'model/params/cnn_dropout': 0.5, 'callbacks/scheduler_callback/use': False, 'callbacks/scheduler_callback/params/_target_': 'src.callbacks.callbacks.SchedulerCallback', 'callbacks/scheduler_callback/params/epoch_start': 40, 'callbacks/scheduler_callback/params/scheduler/name': 'step_lr', 'callbacks/scheduler_callback/params/scheduler/interval': 'epoch', 'callbacks/scheduler_callback/params/scheduler/reduce_on_plateau': False, 'callbacks/scheduler_callback/params/scheduler/params/_target_': 'torch.optim.lr_scheduler.StepLR', 'callbacks/scheduler_callback/params/scheduler/params/step_size': 1, 'callbacks/scheduler_callback/params/scheduler/params/gamma': 0.965, 'callbacks/freeze_callback/use': False, 'callbacks/freeze_callback/params/_target_': 'src.callbacks.callbacks.FreezeCallback', 'callbacks/freeze_callback/params/freeze_rnn': 'None', 'callbacks/freeze_callback/params/freeze_cnn': 'None', 'callbacks/height_increase/use': False, 'callbacks/height_increase/params/_target_': 'src.callbacks.callbacks.ChangeHeight', 'callbacks/height_increase/params/increase_on_epoch': [70, 80, 90, 100], 'callbacks/height_increase/params/height_increment': [8, 16, 24, 32], 'callbacks/height_increase/params/height': 32, 'callbacks/height_increase/params/dyanmic_height_increment': 0, 'callbacks/learning_rate_monitor/use': False, 'callbacks/learning_rate_monitor/params/_target_': 'pytorch_lightning.callbacks.LearningRateMonitor', 'callbacks/learning_rate_monitor/params/logging_interval': 'None', 'callbacks/learning_rate_monitor/params/log_momentum': False, 'callbacks/early_stopping/use': True, 'callbacks/early_stopping/params/_target_': 'pytorch_lightning.callbacks.EarlyStopping', 'callbacks/early_stopping/params/monitor': 'val_loss', 'callbacks/early_stopping/params/patience': 20, 'callbacks/early_stopping/params/mode': 'min', 'callbacks/gpu_stats_monitor/use': False, 'callbacks/gpu_stats_monitor/params/_target_': 'pytorch_lightning.callbacks.GPUStatsMonitor', 'callbacks/gpu_stats_monitor/params/inter_step_time': True, 'callbacks/gpu_stats_monitor/params/intra_step_time': True, 'callbacks/checkpoint_callback/use': True, 'callbacks/checkpoint_callback/params/_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'callbacks/checkpoint_callback/params/dirpath': 'checkpoints', 'callbacks/checkpoint_callback/params/filename': '{epoch}-{val_accuracy:.4f}-{train_accuracy:.4f}-{val_loss:.5f}', 'callbacks/checkpoint_callback/params/save_last': True, 'callbacks/checkpoint_callback/params/mode': 'max', 'callbacks/checkpoint_callback/params/monitor': 'val_accuracy', 'callbacks/checkpoint_callback/params/save_top_k': 2, 'task/name': 'cls', 'task/params/_target_': 'System.RecognitionTraining.src.system.Model_System.TextClassificationSystem', 'task/general/mode': 'max', 'task/general/monitor': 'val_accuracy', 'task/general/early_stop_on': 'val_loss', 'task/general/early_stop_on_mode': 'min', 'task/general/filename': '{epoch}-{val_accuracy:.4f}-{train_accuracy:.4f}-{val_loss:.5f}', 'optimizer/name': 'adam', 'optimizer/_target_': 'torch.optim.Adam', 'optimizer/params/lr': 0.025, 'optimizer/params/weight_decay': 0.0001, 'optimizer/params/betas': [0.9, 0.999], 'logger/name': 'wandb', 'logger/params/_target_': 'pytorch_lightning.loggers.WandbLogger', 'logger/params/project': 'testing_runs', 'logger/params/entity': 'arabic_text', 'logger/params/name': 'cls_adam_res_cnn_cls_2021-02-17_01-20-44', 'logger/params/version': 'cls_adam_res_cnn_cls_2021-02-17_01-20-44', 'logger/params/notes': 'None', 'logger/watch_params/log': 'None', 'logger/watch_params/log_freq': 1000, 'datamodule/name': 'datamodule', 'datamodule/params/_target_': 'src.datamodule.DataModules.DataModule', 'datamodule/params/height': 32, 'datamodule/params/batch_size': 8, 'datamodule/params/dynamic_height': 0, 'datamodule/params/dataset/name': 'ahcd', 'datamodule/params/dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'datamodule/params/dataset/train_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'datamodule/params/dataset/train_dataset/path': '../../../AHCD/Characters/X_train_split.csv', 'datamodule/params/dataset/train_dataset/label_path': '../../../AHCD/Characters/y_train_split.csv', 'datamodule/params/dataset/val_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'datamodule/params/dataset/val_dataset/path': '../../../AHCD/Characters/X_val.csv', 'datamodule/params/dataset/val_dataset/label_path': '../../../AHCD/Characters/y_val.csv', 'datamodule/params/dataset/test_dataset/_target_': 'src.datasets.datasets.CharacterDataset', 'datamodule/params/dataset/test_dataset/path': '../../../AHCD/Characters/X_test.csv', 'datamodule/params/dataset/test_dataset/label_path': '../../../AHCD/Characters/y_test.csv', 'trainer/params/_target_': 'pytorch_lightning.Trainer', 'trainer/params/gpus': 1, 'trainer/params/precision': 16, 'trainer/params/max_epochs': 5, 'trainer/params/reload_dataloaders_every_epoch': True, 'trainer/params/benchmark': True, 'callback_scheduler/name': 'step_lr', 'callback_scheduler/interval': 'epoch', 'callback_scheduler/reduce_on_plateau': False, 'callback_scheduler/params/_target_': 'torch.optim.lr_scheduler.StepLR', 'callback_scheduler/params/step_size': 1, 'callback_scheduler/params/gamma': 0.965, 'general/lr': 0.025, 'general/epochs': 5, 'general/steps': 1344, 'general/decoder': "{1: 'أ', 2: 'ب', 3: 'ت', 4: 'ث', 5: 'ج', 6: 'ح', 7: 'خ', 8: 'د', 9: 'ذ', 10: 'ر', 11: 'ز', 12: 'س', 13: 'ش', 14: 'ص', 15: 'ض', 16: 'ط', 17: 'ظ', 18: 'ع', 19: 'غ', 20: 'ف', 21: 'ق', 22: 'ك', 23: 'ل', 24: 'م', 25: 'ن', 26: 'ه', 27: 'و', 28: 'ي', 29: 'ء'}", 'general/height': 32, 'general/val_log_every': 60, 'general/train_log_every': 150, 'general/ckpt_path': 'None', 'general/transfer_learning': 'None', 'general/start_new_training': 'None', 'general/weight_init': 'None'})

```

