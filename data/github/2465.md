TITLE:
[CLI] : MPI distribution fails to initialise wandb 2465

LABEL:
cli,stale

STATE:
closed

BODY:
**Description** FileExistsError when using mpi distribution with Sagemaker **Wandb features** wandb.init() **How to reproduce** 1. Link to a reproducible script we can run to see the bug ``` ============================================================= [1,1]<stdout>: [1,4]<stdout>: [1,1]<stdout>: [1,3]<stdout>:Problem at: train.py 25 <module> [1,2]<stdout>:Problem at: train.py 25 <module> [1,7]<stdout>:Problem at: train.py 25 <module> [1,4]<stdout>: [1,1]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,0]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,3]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,6]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,2]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,5]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,7]<stderr>:wandb: Currently logged in as: kanishk-aidash (use `wandb login --relogin` to force relogin) [1,6]<stderr>:Thread WriterThread: [1,6]<stderr>:Traceback (most recent call last): [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal_util.py", line 55, in run [1,6]<stderr>: self._run() [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal_util.py", line 105, in _run [1,6]<stderr>: self._process(record) [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal.py", line 333, in _process [1,6]<stderr>: self._wm.write(record) [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/writer.py", line 30, in write [1,6]<stderr>: self.open() [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/writer.py", line 26, in open [1,6]<stderr>: self._ds.open_for_write(self._settings.sync_file) [1,6]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/datastore.py", line 86, in open_for_write [1,6]<stderr>: self._fp = open(fname, open_flags) [1,6]<stderr>:FileExistsError: [Errno 17] File exists: '/opt/ml/code/wandb/run-20210728_033954-kanishk-pytorch-DSMNet-2021-07-28-03-29-08-406-algo-1/run-kanishk-pytorch-DSMNet-2021-07-28-03-29-08-406-algo-1.wandb' [1,0]<stderr>:Thread WriterThread: [1,0]<stderr>:Traceback (most recent call last): [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal_util.py", line 55, in run [1,0]<stderr>: self._run() [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal_util.py", line 105, in _run [1,0]<stderr>: self._process(record) [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/internal.py", line 333, in _process [1,0]<stderr>: self._wm.write(record) [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/writer.py", line 30, in write [1,0]<stderr>: self.open() [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/writer.py", line 26, in open [1,0]<stderr>: self._ds.open_for_write(self._settings.sync_file) [1,0]<stderr>: File "/opt/conda/lib/python3.6/site-packages/wandb/sdk/internal/datastore.py", line 86, in open_for_write [1,0]<stderr>: self._fp = open(fname, open_flags) [1,0]<stderr>:FileExistsError: [Errno 17] File exists: '/opt/ml/code/wandb/run-20210728_033954-kanishk-pytorch-DSMNet-2021-07-28-03-29-08-406-algo-1/run-kanishk-pytorch-DSMNet-2021-07-28-03-29-08-406-algo-1.wandb' ``` 2. Setting: ``` mpi_options = "-verbose --mca orte_base_help_aggregate 0 " smp_parameters = { "optimize": "speed", "microbatches": 12, "partitions": 2, "ddp": True, "pipeline": "interleaved", "overlapping_allreduce": True, "placement_strategy": "cluster", "memory_weight": 0.3, } distribution={"smdistributed": {"modelparallel": {"enabled": True, "parameters": smp_parameters}}, "mpi": { "enabled": True, "processes_per_host": 8, "custom_mpi_options": mpi_options, }, }, ``` 3. Add a zip file with the run folder: Can't share the codebase, but sharing the snippet ``` role = sagemaker.get_execution_role() hyperparameters = {'epochs': 50, 'batch_size': 8, 'test_batch_size': 8, 'learning_rate': 0.0001, 'dataset': 'aidash', 'pretrained': True, 'backend': 'gloo'} mpi_options = "-verbose --mca orte_base_help_aggregate 0 " smp_parameters = { "optimize": "speed", "microbatches": 12, "partitions": 2, "ddp": True, "pipeline": "interleaved", "overlapping_allreduce": True, "placement_strategy": "cluster", "memory_weight": 0.3, } s3_data_path =<datapath> s3_code_location = <codepath> s3_model_path = <modelpath> MAX_RUN_TIME = 259200 estimator = PyTorch(entry_point='train.py', instance_type='ml.p3.16xlarge', tensorboard_output_config=tensorboard_output_config, instance_count=1, role=role, hyperparameters=hyperparameters, sagemaker_session=sagemaker_session, base_job_name='kanishk-pytorch-DSMNet', py_version="py36", framework_version="1.6.0", distribution={ "smdistributed": {"modelparallel": {"enabled": True, "parameters": smp_parameters}}, "mpi": { "enabled": True, "processes_per_host": 8, "custom_mpi_options": mpi_options, }, }, script_mode=True, max_run=MAX_RUN_TIME, source_dir='dorn', code_location=s3_code_location, enable_sagemaker_metrics=True, model_dir = s3_model_path, output_path = s3_model_path, disable_profiler=True, debugger_hook_config=False) estimator.fit({'data_dir': s3_data_path}) ``` **Environment** - OS: Linux ip-172-16-1-72 4.14.225-121.357.amzn1.x86_64 #1 SMP Mon Mar 15 23:52:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux - Environment: AWS Sagemaker - Python Version: 3.6



