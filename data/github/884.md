TITLE:
Threads can only be started once, when 

LABEL:
c:misc

STATE:
closed

BODY:
* Weights and Biases version: wandb, version 0.8.28
* Python version: Python 3.6.10 :: Anaconda, Inc.
* Operating System: Linux

### Description

I was trying to run a model across two separate GPUs. Minimal example is included. I am running this in docker and inside of a jupyter notebook. Lines of "------" denote different cells. 

### What I Did

```
import wandb
from torch import nn
import torch
------
wandb.init()
------
d1=torch.device('cuda',index=1)
d0=torch.device('cuda')
bs=10
class SplitModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.m1=nn.Sequential(
            nn.Conv2d(3,10,7,2),
            nn.ReLU(inplace=True),
            nn.Conv2d(10,32,3,1),
            nn.Flatten(),
            nn.Linear(2592,1),
            nn.Sigmoid()
        )
        self.m2=nn.Sequential(
            nn.Conv2d(3,10,7,2),
            nn.ReLU(inplace=True),
            nn.Conv2d(10,32,3,1),
            nn.Flatten(),
            nn.Linear(2592,1),
            nn.Sigmoid()
        )
    def forward(self,*x):
        x1,x2=x
        return self.m1(x1),self.m2(x2)
class AddLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.loss1=nn.BCELoss()
        self.loss2=nn.BCELoss()
    def forward(self,*x):
        x1,x2=x
        return self.loss1(x1,target=torch.ones_like(x1,device=x1.device))+self.loss2(x2,target=torch.ones_like(x2,device=x2.device)).to(x1.device)

x=torch.randn([bs,3,28,28]).cuda()
model=SplitModel()
model.m1.to(d0)
model.m2.to(d1)
loss_func=AddLoss()
wandb.watch(model)
pred=model(x,x.to(d1))
loss=loss_func(*pred)
loss.backward()

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-3-3d1d6a4c65e8> in <module>
     44 loss=loss_func(*pred)
     45 
---> 46 loss.backward()

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    164                 products. Defaults to ``False``.
    165         """
--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    167 
    168     def register_hook(self, hook):

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/wandb_torch.py in backward_hook(module, input, output)
    357                     graph.loaded = True
    358                     if wandb.run:
--> 359                         wandb.run.summary["graph_%i" % graph_idx] = graph
    360                     else:
    361                         wandb.termwarn(

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/summary.py in __setitem__(self, k, v)
    136         self._locked_keys.add(k)
    137 
--> 138         self._root._write()
    139 
    140         return v

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/summary.py in _write(self, commit)
    370             self._h5 = None
    371         if wandb.run and wandb.run._jupyter_agent:
--> 372             wandb.run._jupyter_agent.start()
    373 
    374 

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/jupyter.py in start(self)
    127             # we update the runs history._steps in extreme hack fashion
    128             # TODO: this reserves a bigtime refactor
--> 129             new_step = self.rm.init_run(dict(os.environ))
    130             if new_step:
    131                 wandb.run.history._steps = new_step + 1

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/run_manager.py in init_run(self, env)
    963             logger.info("upserting run before process can begin, waiting at most %d seconds" % InternalApi.HTTP_TIMEOUT)
    964             async_upsert = util.async_call(self._upsert_run, timeout=InternalApi.HTTP_TIMEOUT)
--> 965             _, self._upsert_run_thread = async_upsert(True, storage_id, env)
    966             if self._upsert_run_thread.is_alive():
    967                 logger.error("Failed to connect to W&B servers after %i seconds.\

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/wandb/util.py in wrapper(*args, **kwargs)
    774             result = q.get(True, timeout)
    775             if isinstance(result, Exception):
--> 776                 six.reraise(type(result), result, sys.exc_info()[2])
    777             return result, thread
    778         except queue.Empty:

~/anaconda3/envs/fastai2/lib/python3.6/site-packages/six.py in reraise(tp, value, tb)
    700                 value = tp()
    701             if value.__traceback__ is not tb:
--> 702                 raise value.with_traceback(tb)
    703             raise value
    704         finally:

RuntimeError: threads can only be started once
```


