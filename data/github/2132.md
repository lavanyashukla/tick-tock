TITLE:
[CLI] Exception Occurs When Manually Syncing While Training

LABEL:
cli

STATE:
closed

BODY:
## Exception Occurs When Running `wandb sync --sync-all`

This occurs only if you have run `wandb offline` before starting training, then run `wandb online` and `wandb sync --sync-all` _while_ training continues. 

### Involves CLI features:
- `wandb offline`
- `wandb online`
- `wandb sync`

## Reproducing the bug on wandb, version 0.10.27

### Video
Here is a video demonstrating the exact steps taken to illustrate the issue.
https://www.dropbox.com/s/0w2avv68h41uuvn/2021-04-28_10-18-49.mkv


### Script
You will need a dataset to use this script exactly. I have pre-prepared one [here](https://www.dropbox.com/sh/5b2qz9gjytpjgl4/AACGD7F__UoIPLKRnfun9boEa?dl=0) (CUBS) which is relatively small. Unzip the file and point the `--image_text_folder` cli arg of `train_dalle.py` at it.


```bash
#!/bin/bash

# Setup conda for the first time
conda init
source ~/.bashrc

# Create conda virtual env for test
conda create -n test_wandb_corrupted_sync

# Install (as of present) the latest version of wandb (0.10.27)
pip install wandb --upgrade

# Clone a pytorch codebase used to train with
git clone https://github.com/lucidrains/DALLE-pytorch
cd DALLE-pytorch
python setup.py install

# Go offline
wandb offline

# Begin training (you will need a GPU for the repo I listed)
python train_dalle.py --taming --truncate_captions --image_text_folder CUBS

# Try to sync (perhaps as a mistake)
wandb sync --sync-all
```
Will generate:

```sh
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.8/site-packages/wandb/sync/sync.py", line 202, in run
    ds.open_for_scan(sync_item)
  File "/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py", line 99, in open_for_scan
    self._read_header()
  File "/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py", line 166, in _read_header
    ident, magic, version = struct.unpack("<4sHB", header)
struct.error: unpack requires a buffer of 7 bytes
```

Trying to go back online while training continues doesn't resolve the issue:

```sh
wandb online
wandb sync --sync-all
```

Will again generate:
```sh
wandb sync --sync-all
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.8/site-packages/wandb/sync/sync.py", line 202, in run
    ds.open_for_scan(sync_item)
  File "/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py", line 99, in open_for_scan
    self._read_header()
  File "/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py", line 166, in _read_header
    ident, magic, version = struct.unpack("<4sHB", header)
struct.error: unpack requires a buffer of 7 bytes
```


### **Environment**
- OS: 
```sh
uname -r
5.11.0-7612-generic
```
- Docker: `pytorch/pytorch:1.8.1-cuda11.1-cudnn8-devel`
- Python Version: 3.8.5
- CUDA Toolkit 11.1
```sh
Cuda compilation tools, release 11.1, V11.1.105
Build cuda_11.1.TC455_06.29190527_0
```
- conda version: 4.10.1
- pip version 21.0.1

