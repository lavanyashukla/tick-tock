TITLE:
wandb: ERROR Run yhjvnf8d errored: KeyError('sentence_id')[CLI]: 

LABEL:
cli

STATE:
closed

BODY:
### Describe the bug

<!--- Description of the issue below  -->
Hi everyone, 

i try to do some hyperparameter tuning on a Simpletransformers NER Model. I start from the exemple of tuning in the Simpletransformers tips and tricks. 

link : https://simpletransformers.ai/docs/tips-and-tricks/#hyperparameter-optimization 

The exemple work fine but when I change the model and the data but keep the same workflow I have an error I can't understand. 

<!--- A minimal code snippet between the quotes below  -->
```python 

import logging
import pandas as pd
import sklearn

import wandb
from simpletransformers.ner import NERModel


tags = ['B-LOC', 'I-LOC', 'O']

sweep_config = {
    "method": "random",  # grid, random, bayes
    "metric": {"name": "recall", "goal": "maximize"},
    "parameters": {
        "num_train_epochs": {"values": [3, 4, 5, 8]},
        "learning_rate": {"min": 2.66545e-05, "max": 4.82692e-05},
        "weight_decay": {"values": [0.097684, 0.294078 , 0.0520186]},
    },
}

sweep_id = wandb.sweep(sweep_config, project="Simple Sweep")

logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
train_df = pd.read_csv("./data_NER/prepare_sentence_train_100_EOS_3000_PBT.txt", sep=' ')
train_df.columns = ["tokens", "labels"]

# Preparing eval data
eval_df = pd.read_csv("./data_NER/prepare_sentence_val_100_EOS_3000_PBT.txt", sep=' ')
eval_df.columns = ["tokens", "labels"]

model_args = NERModel( model_type='camembert', model_name='camembert-base', labels =tags)
model_args.reprocess_input_data = True
model_args.overwrite_output_dir = True
model_args.evaluate_during_training = True
model_args.manual_seed = 4
model_args.use_multiprocessing = True
model_args.train_batch_size = 16
model_args.eval_batch_size = 8
model_args.labels_list = ['B-LOC', 'I-LOC', 'O']   # mystake previously made ["true", "false"]
model_args.wandb_project = "Simple Sweep"

def train():
    # Initialize a new wandb run
    wandb.init()

    # Create a TransformerModel
    model = NERModel(
        model_type='camembert', 
        model_name='camembert-base', 
        labels = tags,
        use_cuda=True,
        args=model_args,
        sweep_config=wandb.config,
    )

    # Train the model
    model.train_model(train_df, eval_df=eval_df)

    # Evaluate the model
    model.eval_model(eval_df)

    # Sync wandb
    wandb.join()


wandb.agent(sweep_id, train)

```

<!--- A full traceback of the exception in the quotes below -->
```shell

Create sweep with ID: e0vtpjlw
Sweep URL: https://wandb.ai/username/Simple%20Sweep/sweeps/e0vtpjlw
Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: Agent Starting Run: kmbc50ot with config:
wandb: 	learning_rate: 3.9629316309755294e-05
wandb: 	num_train_epochs: 3
wandb: 	weight_decay: 0.0520186
Tracking run with wandb version 0.12.14
Run data is saved locally in /opt/app/data/Dedoublonnage V2/Notebook/wandb/run-20220413_103500-kmbc50ot
Syncing run [generous-sweep-1](https://wandb.ai/thomasseb/Simple%20Sweep/runs/kmbc50ot) to [Weights & Biases](https://wandb.ai/thomasseb/Simple%20Sweep) ([docs](https://wandb.me/run))
Sweep page: https://wandb.ai/thomasseb/Simple%20Sweep/sweeps/e0vtpjlw
Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
Synced generous-sweep-1: https://wandb.ai/thomasseb/Simple%20Sweep/runs/kmbc50ot
Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
Find logs at: ./wandb/run-20220413_103500-kmbc50ot/logs

the log file : 

2022-04-13 10:35:00,645 INFO    Thread-302:31319 [wandb_setup.py:_flush():75] Loading settings from /root/.config/wandb/settings
2022-04-13 10:35:00,646 INFO    Thread-302:31319 [wandb_setup.py:_flush():75] Loading settings from wandb/settings
2022-04-13 10:35:00,646 INFO    Thread-302:31319 [wandb_setup.py:_flush():75] Loading settings from environment variables: {'api_key': '***REDACTED***', 'project': 'Simple Sweep', 'entity': 'thomasseb', 'root_dir': '/opt/app/data/Dedoublonnage V2/Notebook', 'sweep_id': 'e0vtpjlw', 'run_id': 'kmbc50ot', 'sweep_param_path': '/opt/app/data/Dedoublonnage V2/Notebook/wandb/sweep-e0vtpjlw/config-kmbc50ot.yaml'}
2022-04-13 10:35:00,646 INFO    Thread-302:31319 [wandb_setup.py:_flush():75] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2022-04-13 10:35:00,646 INFO    Thread-302:31319 [wandb_init.py:_log_setup():438] Logging user logs to /opt/app/data/Dedoublonnage V2/Notebook/wandb/run-20220413_103500-kmbc50ot/logs/debug.log
2022-04-13 10:35:00,647 INFO    Thread-302:31319 [wandb_init.py:_log_setup():439] Logging internal logs to /opt/app/data/Dedoublonnage V2/Notebook/wandb/run-20220413_103500-kmbc50ot/logs/debug-internal.log
2022-04-13 10:35:00,647 INFO    Thread-302:31319 [wandb_init.py:init():472] calling init triggers
2022-04-13 10:35:00,648 INFO    Thread-302:31319 [wandb_init.py:init():476] wandb.init called with sweep_config: {'learning_rate': 3.9629316309755294e-05, 'num_train_epochs': 3, 'weight_decay': 0.0520186}
config: {}
2022-04-13 10:35:00,648 INFO    Thread-302:31319 [wandb_init.py:init():525] starting backend
2022-04-13 10:35:00,648 INFO    Thread-302:31319 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2022-04-13 10:35:00,650 INFO    Thread-302:31319 [backend.py:ensure_launched():219] starting backend process...
2022-04-13 10:35:00,779 INFO    Thread-302:31319 [backend.py:ensure_launched():225] started backend process with pid: 652
2022-04-13 10:35:00,780 INFO    Thread-302:31319 [wandb_init.py:init():534] backend started and connected
2022-04-13 10:35:00,795 INFO    Thread-302:31319 [wandb_run.py:_config_callback():1129] config_cb None None {'learning_rate': 3.9629316309755294e-05, 'num_train_epochs': 3, 'weight_decay': 0.0520186}
2022-04-13 10:35:00,800 INFO    Thread-302:31319 [wandb_run.py:_label_probe_notebook():1082] probe notebook
2022-04-13 10:35:00,801 INFO    Thread-302:31319 [wandb_run.py:_label_probe_notebook():1092] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2022-04-13 10:35:00,801 INFO    Thread-302:31319 [wandb_init.py:init():598] updated telemetry
2022-04-13 10:35:00,802 INFO    Thread-302:31319 [wandb_init.py:init():629] communicating run to backend with 30 second timeout
2022-04-13 10:35:01,677 INFO    Thread-302:31319 [wandb_run.py:_on_init():1922] communicating current version
2022-04-13 10:35:01,741 INFO    Thread-302:31319 [wandb_run.py:_on_init():1926] got version response 
2022-04-13 10:35:01,741 INFO    Thread-302:31319 [wandb_init.py:init():660] starting run threads in backend
2022-04-13 10:35:03,055 INFO    Thread-302:31319 [wandb_run.py:_console_start():1896] atexit reg
2022-04-13 10:35:03,055 INFO    Thread-302:31319 [wandb_run.py:_redirect():1769] redirect: SettingsConsole.WRAP
2022-04-13 10:35:03,055 INFO    Thread-302:31319 [wandb_run.py:_redirect():1806] Wrapping output streams.
2022-04-13 10:35:03,056 INFO    Thread-302:31319 [wandb_run.py:_redirect():1830] Redirects installed.
2022-04-13 10:35:03,056 INFO    Thread-302:31319 [wandb_init.py:init():685] run started, returning control to user process
2022-04-13 10:35:06,371 INFO    Thread-302:31319 [wandb_run.py:_finish():1684] finishing run thomasseb/Simple Sweep/kmbc50ot
2022-04-13 10:35:06,372 INFO    Thread-302:31319 [wandb_run.py:_atexit_cleanup():1865] got exitcode: 1
2022-04-13 10:35:06,372 INFO    Thread-302:31319 [wandb_run.py:_restore():1837] restore
2022-04-13 10:35:06,597 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 670
  total_bytes: 670
}

2022-04-13 10:35:06,833 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 1
}
pusher_stats {
  uploaded_bytes: 670
  total_bytes: 670
}

2022-04-13 10:35:07,697 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 4
}
pusher_stats {
  uploaded_bytes: 670
  total_bytes: 7451
}

2022-04-13 10:35:07,801 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 670
  total_bytes: 8504
}

2022-04-13 10:35:07,905 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,010 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,113 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,214 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,317 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,420 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:08,633 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}

2022-04-13 10:35:11,819 INFO    Thread-302:31319 [wandb_run.py:_on_finish():1995] got exit ret: done: true
exit_result {
}
file_counts {
  wandb_count: 5
}
pusher_stats {
  uploaded_bytes: 8504
  total_bytes: 8504
}
local_info {
}

2022-04-13 10:35:13,048 INFO    Thread-302:31319 [wandb_run.py:_footer_history_summary_info():3087] rendering history
2022-04-13 10:35:13,048 INFO    Thread-302:31319 [wandb_run.py:_footer_history_summary_info():3116] rendering summary
2022-04-13 10:35:13,049 INFO    Thread-302:31319 [wandb_run.py:_footer_sync_info():3044] logging synced files

```


### Additional Files

_No response_

### Environment

WandB version: 0.12.14

OS: Windows 10 

Python version: 3.7.4

Versions of relevant libraries:


### Additional Context

_No response_

