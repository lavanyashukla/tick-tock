TITLE:
wandb_torch.py causing random crashes

LABEL:
c:misc

STATE:
closed

BODY:
Hi,
I am facing crashes when using wandb and fastai.
Can anyone cast some light on this?
Thanks

* Weights and Biases version: 0.8.22
* Python version: 3.6.9
* Operating System : Linux

```
=== Software === 
python        : 3.6.9
fastai        : 1.0.60
fastprogress  : 0.2.2
torch         : 1.4.0
nvidia driver : 440.44
torch cuda    : 10.1 / is available
torch cudnn   : 7603 / is enabled

=== Hardware === 
nvidia gpus   : 2
torch devices : 2
  - gpu0      : 11019MB | GeForce RTX 2080 Ti
  - gpu1      : 11016MB | GeForce RTX 2080 Ti

=== Environment === 
platform      : Linux-5.3.0-26-generic-x86_64-with-Ubuntu-18.04-bionic
distro        : #28~18.04.1-Ubuntu SMP Wed Dec 18 16:40:14 UTC 2019
conda env     : Unknown
python        : /usr/bin/python3
sys.path      : /home/jacob/.local/lib/python3.6/site-packages/git/ext/gitdb
/usr/lib/python36.zip
/usr/lib/python3.6
/usr/lib/python3.6/lib-dynload

/home/jacob/.local/lib/python3.6/site-packages
/usr/local/lib/python3.6/dist-packages
/usr/lib/python3/dist-packages
/home/jacob/.local/lib/python3.6/site-packages/IPython/extensions
/home/jacob/.ipython
/home/jacob/.local/lib/python3.6/site-packages/gitdb/ext/smmap
```

### Description

I am training a fastai text classifier (ulmfit), and get random crashes from the wandb client. 

### What I Did
Here's my model definition:
```
all_metrics = [accuracy, KappaScore(),  bacc, f1binary]
learn_c = text_classifier_learner(data_clas, AWD_LSTM, pretrained=False, drop_mult=0.4, 
                                  metrics=all_metrics).to_fp16()

```
I was running this:

```
callbacks = [CSVLogger(learn_c, filename=f'LOG-{nome}', append=True), SaveModelCallback(learn_c, every='improvement', monitor='kappa_score', name=f'BEST-{nome}'), WandbCallback(learn_c, save_model=False)]
```

and, after a random number of epochs, get this error:

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-31-7b71656206cb> in <module>
      2     learn_c.fit_one_cycle(3, lr, wd=wd,
      3                           moms=(0.8,0.7),
----> 4                           callbacks=callbacks)
      5 #SaveModelCallback(learn_c, monitor='bacc', name=nome, mode='max'),

~/.local/lib/python3.6/site-packages/fastai/utils/ipython.py in __exit__(self, exc_type, exc_val, exc_tb)
     62         traceback.clear_frames(exc_tb)
     63         gc.collect()
---> 64         raise exc_type(exc_val).with_traceback(exc_tb) from None

<ipython-input-31-7b71656206cb> in <module>
      2     learn_c.fit_one_cycle(3, lr, wd=wd,
      3                           moms=(0.8,0.7),
----> 4                           callbacks=callbacks)
      5 #SaveModelCallback(learn_c, monitor='bacc', name=nome, mode='max'),

~/.local/lib/python3.6/site-packages/fastai/train.py in fit_one_cycle(***failed resolving arguments***)
     21     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,
     22                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))
---> 23     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
     24 
     25 def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,

~/.local/lib/python3.6/site-packages/fastai/basic_train.py in fit(***failed resolving arguments***)
    198         else: self.opt.lr,self.opt.wd = lr,wd
    199         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)
--> 200         fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
    201 
    202     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

~/.local/lib/python3.6/site-packages/fastai/basic_train.py in fit(***failed resolving arguments***)
     99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
--> 101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)
    102                 if cb_handler.on_batch_end(loss): break
    103 

~/.local/lib/python3.6/site-packages/fastai/basic_train.py in loss_batch(***failed resolving arguments***)
     32     if opt is not None:
     33         loss,skip_bwd = cb_handler.on_backward_begin(loss)
---> 34         if not skip_bwd:                     loss.backward()
     35         if not cb_handler.on_backward_end(): opt.step()
     36         if not cb_handler.on_step_end():     opt.zero_grad()

~/.local/lib/python3.6/site-packages/torch/tensor.py in backward(***failed resolving arguments***)
    193                 products. Defaults to ``False``.
    194         """
--> 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    196 
    197     def register_hook(self, hook):

~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(***failed resolving arguments***)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

~/.local/lib/python3.6/site-packages/wandb/wandb_torch.py in <lambda>(***failed resolving arguments***)
    217             self.log_tensor_stats(grad.data, name)
    218 
--> 219         handle = var.register_hook(lambda grad: _callback(grad, log_track))
    220         self._hook_handles[name] = handle
    221         return handle

~/.local/lib/python3.6/site-packages/wandb/wandb_torch.py in _callback(***failed resolving arguments***)
    215             if not log_track_update(log_track):
    216                 return
--> 217             self.log_tensor_stats(grad.data, name)
    218 
    219         handle = var.register_hook(lambda grad: _callback(grad, log_track))

~/.local/lib/python3.6/site-packages/wandb/wandb_torch.py in log_tensor_stats(***failed resolving arguments***)
    189         tmin = flat.min().item()
    190         tmax = flat.max().item()
--> 191         tensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)
    192         tensor = tensor.cpu().clone().detach()
    193         bins = torch.linspace(tmin, tmax, steps=self._num_bins + 1)

RuntimeError: range of [-inf, 376] is not finite
```


