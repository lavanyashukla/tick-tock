TITLE:
[Q] Explanation on rate limits, and help maximizing total parallel runs

LABEL:
c:misc

STATE:
closed

BODY:
I don't really understand what is the exact nature of the rate limits in place.

Checking out all the relevant github issues, it has been pointed out that the rate limit is not based on the number of logs per second.  The documentation (found here https://docs.wandb.ai/guides/track/limits#rate-limits) says the following, which seems to maybe confirm this, but also leaves me confused about a few things.

> Rate Limits

> The W&B API is rate limited by IP and API key. Free accounts are restricted to 50 requests per minute. Paid accounts are restricted to 200 requests per minute. This rate allows you to run approximately 15 processes in parallel and have them report without being throttled. If the wandb client detects it's being limited, it will backoff and retry sending the data in the future. If you need to run more than 15 processes in parallel send an email to [contact@wandb.com](mailto:contact@wandb.com).

> For sweeps, we support up to 20 parallel agents.

I have a few questions about the rate limit:

- "Free accounts are restricted to 50 requests per minute".  50 requests of what?  Does not seem to be related to logs per minute.  Is it runs started per minute?
- "This rate allows you to run approximately 15 processes in parallel and have them report without being throttled."  How is the number of 15 processes obtained, without knowing how many requests per minute each process makes?  Still related to the above question of "50 requests of what".  This seems to void the possibility that the above was 50 runs started per minute, since 1 run would be 1 process.

Then I have a few questions about my specific use case.  I try to run hyper-parameter grid-search, which requires me to execute many learning runs, each of which is slow and may take up to a day or more, due to the application setting.  For that reason, I need to maximize the number of parallel runs I can have running at the same time, as much as possible, even at the cost of drastically reducing the number of logs that each run makes.  Ideally, I'd have up to 1000 at the same time, but I can live with less than that, as long as it's at least a few hundred;  let's say 500.  Currently, the wandb rate limits (and/or the inability to resume offline runs) are my main obstacle in achieving this.  Even if I only make 50 logs per 24 hours per run, which would "only" amount to about 1 log every 4 seconds on average for all 500 runs in total, I keep getting `Filestream rate exceeded` errors and delays.  I used to be able to use offline runs to address this, but I also need to be able to checkpoint and resume runs, and that functionality seems to have stopped working for offline runs.  What is the best way to maximize the number of independent runs I can have at the same time?

