TITLE:
[Feature] Logging a TF model's configuration

LABEL:
feature_request

STATE:
closed

BODY:
**Is your feature request related to a problem? Please describe.**
Not related to a problem, just for convenience I'd like to log the model's configuration (mainly aiming for kernels, kernel sizes, dense units, that kind of stuff) via `wandb.log()`. This would allow easier comparison of model architectures.

**Describe the solution you'd like**
See this MVE:

```
import tensorflow as tf
import wandb
in_ = tf.keras.layers.Input(shape=(30, 30, 3))
conv = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3))(in_)
model = tf.keras.Model(in_, conv)

conf = model.get_config()

print(conf)

wandb.init(config=conf)
# or
wandb.log({'model_config':conf})
```
which currently throws

```
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1502, in _atexit_cleanup
    self._on_finish()
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 1638, in _on_finish
    self.history._flush()
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/sdk/wandb_history.py", line 59, in _flush
    self._callback(row=self._data, step=self._step)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 805, in _history_callback
    self._backend.interface.publish_history(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 226, in publish_history
    item.value_json = json_dumps_safer_history(v)  # type: ignore
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/util.py", line 655, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/json/__init__.py", line 234, in dumps
    return cls(
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/site-packages/wandb/util.py", line 622, in default
    return json.JSONEncoder.default(self, obj)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/we4bee/lib/python3.8/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type dict is not JSON serializable
```

**Describe alternatives you've considered**
I am currently using something like
```
def get_default_model_config():
    config = {
        'num_conv1': 24,  # conv should be multiple of 8
        'num_conv2': 32,
        'num_conv3': 64,
        'num_conv4': 128,
        'pool_size': (2, 2, 2),
        'kernel_size': (3, 3),
        'dropout1': 0.15,
        'dropout2': 0.15,
        'dropout3': 0.15,
        'dropout4': 0.15,
        'win_length': 1024,
        'n_fft': 2048,
        'n_mels': 60,
        'frame_length': 41,
        'hop_length': 512,
        'dropout5': 0.15,
        'num_dense': 128,  # dense should be multiple of 8
        'embedding_dim': 64,
    }

    return config

wandb.init(config=get_default_model_config())
```

this is a bit hacky.


