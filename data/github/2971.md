TITLE:
[CLI] Resumed runs lose pre-resumed data

LABEL:
cli

STATE:
closed

BODY:
**Description**
I'm trying to use wandb in a computing cluster setting which poses some limitations:  I have to run everything offline, and I have time limits on all my processes.  Offline wandb runs on their own work fine, but resuming them is causing some issues.  I'm not 100% sure if the issue is in the data being lost altogether, or technically it's also possible that this is only a visualization issue on the wandb website (although I doubt that).

Here is my pipeline:

1. I start some offline runs.  They work fine and always complete without any issue.  Before the time limit runs out, each run saves a checkpoint with a snapshot of the run, needed to pick the work up, and then ends properly, achieving "finished" status.
2. I sync the data, and view it on the wandb website:

![image](https://user-images.githubusercontent.com/1794938/144137612-415f0f0a-47c6-42b5-a264-cd261ebcdca8.png)

(note that the logging starts at 50k because of internal program logic;  this is correct as it stands).

3. now I resume the runs;  to do this, I load the snapshot, which among other things contains the run id, and use wandb.init(..., resume='must', id=run_id_from_snapshot).  It looks like the run is resumed correctly, and there are no other issues with it.  Before the time limit runs out, each run saves a checkpoint with the snapshot of the run, and ends properly, achieving "finished" status again.

4. I sync the data, and view it on the wandb website:

![image](https://user-images.githubusercontent.com/1794938/144139522-01eab18b-e3f2-467d-a4d6-5e148bd3ebc3.png)

These are the same runs as shown in the first image.  You'll note that only one of them is now starting from 50k, as it should.  All the other runs, seem like they are starting either from the point where they were resumed, or, in the case of the orange line, between the real start (50k) and the point where they resumed, i.e., the previous data seems lost.

5. I repeat the process again:  resume the runs, then sync the data, and view it on the wandb website:

![image](https://user-images.githubusercontent.com/1794938/144142807-9f55863e-d721-48ee-89c2-c658cc0cff23.png)

Again, same issue is repeating itself (with different runs now demonstrating the issue, i.e., the orange and gray lines now are "pushed back" and have lost data compared to what was available before resuming).

**Wandb features**
I primarily just use wandb.init() to initialize a run, and as a context manager to also finish it, and wandb.log to log data.

**How to reproduce**
Don't have a MWE yet, but I could make one if required.

**Environment**
- OS: Red Hat 4.8.5-44
- Environment: Command line execution on SLURM-based computing cluster
- Python Version: 3.8.3


