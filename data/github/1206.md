TITLE:
Selected runs are not logging media for the key: score per update, but instead are logging type

LABEL:
bug

STATE:
closed

BODY:
* Weights and Biases version: 0.9.5
* Python version:  3.8.5
* Operating System: Windows 10

### Description

I was trying to log some values using `wandb.log()` but got one of the windows of my logs said this instead as shown in the attached file.
![error](https://user-images.githubusercontent.com/59944048/90507212-30cae480-e15e-11ea-8080-5c9abb2a71ee.png)
The other logs seems to work fine except the one of `np.mean(total_score_per_update)`
![error1](https://user-images.githubusercontent.com/59944048/90507754-18a79500-e15f-11ea-891f-61cab3c476c9.png)

### What I Did

```
            for self.step in range(0, num_steps):
                self.states[self.step] = next_state
                self.masks[self.step] = next_done
                # given a state agent selects an action
                with torch.no_grad():
                    next_state, reward, done, _ = self.select_make_action(self.states[self.step])
                    self.rewards[self.step] = reward
                    next_done = torch.Tensor(done).to(self.device)
                    next_state = torch.Tensor(next_state).to(self.device)
                if self.step == 0:
                    score = reward
                else:
                    score += reward
                total_score_per_update.append(score)
                score_avg.append(score)
                if len(score_avg) == score_threshold:
                    if np.mean(score_avg) > -0.5:
                        print("Environment is solved and achieved an average of {} for the last {} episodes"
                              .format(np.mean(score_avg), len(score_avg)))
                        end_time = time()
                        print("It took {} seconds to solve the environment"
                              .format(end_time - start_time))
                        break
            if len(score_avg) == score_threshold:
                if np.mean(score_avg) > -0.5:
                    break
            actor_loss, critic_loss = self.update_model(next_state)
            wandb.log({"actor loss": actor_loss, "critic loss": critic_loss,
                       "actor learning rate": actor_lr_now,
                       "critic learning rate": critic_lr_now, 
                       "score per update": np.mean(total_score_per_update)})

```


