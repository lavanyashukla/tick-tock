TITLE:
pytorch wandb.watch(model) leads to ValueError

LABEL:
c:misc

STATE:
closed

BODY:
* Weights and Biases version: >=0.8.23
* Python version: 3.6.5
* Operating System: CentOS Linux release 7.4.1708 (Core)

### Description

I try to run a pytorch model on our Jupyter Server and with the new wandb version (>= 0.8.23) I get the following error when `wandb.watch(model)` is enabled. With wandb version 0.8.22 everything works fine.

### What I Did
I started training and called before in the initialization`wandb.watch(model)`. 
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-7-041e2033e90a> in <module>()
----> 1 trainer.run()

~/vae/trainer.py in run(self)
     87             print(f"Epoch {epoch}/{self.n_epochs-1} started.")
     88             epoch_start = time.time()
---> 89             self.train(epoch)
     90             self.test(epoch)
     91             print(f"Epoch {epoch}/{self.n_epochs-1} finished after {(time.time() - epoch_start)/60:.2} minutes.")

~/vae/trainer.py in train(self, epoch)
    109                     recon_images, images, mu, logvar, pred_param, param, self.config.rec_img_reduction, self.config.beta, self.config.gamma_dec, self.config.gamma_mlp, self.config.sigmoid_var, self.config.c_max, self.config.c_fn)
    110 
--> 111             loss.backward()
    112             self.optimizer.step()
    113 

~/.local/lib/python3.6/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    164                 products. Defaults to ``False``.
    165         """
--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    167 
    168     def register_hook(self, hook):

~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

~/.local/lib/python3.6/site-packages/wandb/wandb_torch.py in backward_hook(module, input, output)
    357                     graph.loaded = True
    358                     if wandb.run:
--> 359                         wandb.run.summary["graph_%i" % graph_idx] = graph
    360                     else:
    361                         wandb.termwarn(

~/.local/lib/python3.6/site-packages/wandb/summary.py in __setitem__(self, k, v)
    136         self._locked_keys.add(k)
    137 
--> 138         self._root._write()
    139 
    140         return v

~/.local/lib/python3.6/site-packages/wandb/summary.py in _write(self, commit)
    370             self._h5 = None
    371         if wandb.run and wandb.run._jupyter_agent:
--> 372             wandb.run._jupyter_agent.start()
    373 
    374 

~/.local/lib/python3.6/site-packages/wandb/jupyter.py in start(self)
    120     def start(self):
    121         if self.paused:
--> 122             self.rm = RunManager(wandb.run, output=False, cloud=wandb.run.mode != "dryrun")
    123             wandb.run.api._file_stream_api = None
    124             self.rm.mirror_stdout_stderr()

~/.local/lib/python3.6/site-packages/wandb/run_manager.py in __init__(self, run, project, tags, cloud, output, port)
    506         # Calling .start() on _meta and _system_stats will spin a thread that reports system stats every 30 seconds
    507         self._system_stats = stats.SystemStats(run, self._api)
--> 508         self._meta = meta.Meta(self._api, self._run.dir)
    509         self._meta.data["jobType"] = self._run.job_type
    510         self._meta.data["mode"] = self._run.mode

~/.local/lib/python3.6/site-packages/wandb/meta.py in __init__(self, api, out_dir)
     38             self.data = {}
     39         self.lock = threading.Lock()
---> 40         self.setup()
     41         self._thread = threading.Thread(target=self._thread_body)
     42         self._thread.daemon = True

~/.local/lib/python3.6/site-packages/wandb/meta.py in setup(self)
    101                 try:
    102                     try:
--> 103                         old_alarm = signal.signal(signal.SIGALRM, alarm_handler)
    104                         signal.alarm(25)
    105                         self._setup_code_git()

/trinity/shared/pkg/devel/python/3.6.5/lib/python3.6/signal.py in signal(signalnum, handler)
     45 @_wraps(_signal.signal)
     46 def signal(signalnum, handler):
---> 47     handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
     48     return _int_to_enum(handler, Handlers)
     49 

ValueError: signal only works in main thread
```
Hope you have a hint for me.

